<!DOCTYPE html>
<html lang="ru" data-vue-meta="%7B%22lang%22:%7B%22ssr%22:%22ru%22%7D%7D">
<head >
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover">
  <title>Юрий Бушмелев «Карта граблей на поле сбора и доставки логов» — расшифровка доклада / Хабр</title>
  <style>
    /* cyrillic-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSxf6TF0.woff2) format('woff2');
      unicode-range: U+0460-052F, U+1C80-1C88, U+20B4, U+2DE0-2DFF, U+A640-A69F, U+FE2E-FE2F;
    }

    /* cyrillic */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveQhf6TF0.woff2) format('woff2');
      unicode-range: U+0400-045F, U+0490-0491, U+04B0-04B1, U+2116;
    }

    /* latin-ext */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveSBf6TF0.woff2) format('woff2');
      unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
    }

    /* latin */
    @font-face {
      font-family: 'Fira Sans';
      font-style: normal;
      font-weight: 500;
      font-display: swap;
      src: url(https://fonts.gstatic.com/s/firasans/v11/va9B4kDNxMZdWfMOD5VnZKveRhf6.woff2) format('woff2');
      unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
    }
  </style>
  <link rel="preload" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" as="script"><link rel="preload" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css" as="style"><link rel="preload" href="https://assets.habr.com/habr-web/js/app.c0af73e7.js" as="script">
  <link rel="stylesheet" href="https://assets.habr.com/habr-web/css/chunk-vendors.e7843cc0.css"><link rel="stylesheet" href="https://assets.habr.com/habr-web/css/app.02ee25a4.css">
  <script>window.i18nFetch = new Promise((res, rej) => {
          const xhr = new XMLHttpRequest();
          xhr.open('GET', '/js/i18n/ru-compiled.85eb77f0b17c8235e7b64b9f81ea5ec2.json');
          xhr.responseType = 'json';
          xhr.onload = function(e) {
            if (this.status === 200) {
              res({ru: xhr.response});
            } else {
              rej(e);
            }
          };
          xhr.send();
        });</script>
  
  <script data-vue-meta="ssr" src="/js/ads.js" onload="window['zhY4i4nJ9K'] = true" data-vmid="checkad"></script><script data-vue-meta="ssr" type="application/ld+json" data-vmid="ldjson-schema">{"@context":"http:\/\/schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/habr.com\/ru\/post\/450098\/"},"headline":"Юрий Бушмелев «Карта граблей на поле сбора и доставки логов» — расшифровка доклада","datePublished":"2019-04-30T09:54:36+03:00","dateModified":"2019-10-24T16:48:25+03:00","author":{"@type":"Person","name":"gecube"},"publisher":{"@type":"Organization","name":"Habr","logo":{"@type":"ImageObject","url":"https:\/\/habrastorage.org\/webt\/a_\/lk\/9m\/a_lk9mjkccjox-zccjrpfolmkmq.png"}},"description":"Логи &mdash; важная часть системы, позволяющая понять, что она работает (либо не работает), как ожидается. В условиях микросервисной архитектуры работа с логами станов...","url":"https:\/\/habr.com\/ru\/post\/450098\/#post-content-body","about":["h_sys_admin","h_s_admin","h_devops","f_admin"],"image":["https:\/\/habrastorage.org\/webt\/_9\/te\/o5\/_9teo5cvnhsihs4lyyyc_8pcx-m.png","https:\/\/habrastorage.org\/webt\/gy\/fj\/du\/gyfjduafaipfx1ay5efm8xpwtdc.png","https:\/\/habrastorage.org\/webt\/vq\/kr\/yt\/vqkrytwk4c_gjs9fza8_zn9hanu.png","https:\/\/habrastorage.org\/webt\/me\/fd\/7d\/mefd7deeshbhsvsjb8n7dh81ok4.png","https:\/\/habrastorage.org\/webt\/0m\/f8\/4r\/0mf84rxvsn0ewrqui_4egxgb2hk.png","https:\/\/habrastorage.org\/webt\/le\/7-\/_n\/le7-_n8o7wl8nh4g0qadwz-jucq.png","https:\/\/habrastorage.org\/webt\/kn\/id\/o2\/knido22_ecpa0cgvfjzissz3fei.png","https:\/\/habrastorage.org\/webt\/qu\/zg\/z0\/quzgz0a21pgjdb0o8ek5d3nxmwc.png","https:\/\/habrastorage.org\/webt\/tu\/b_\/xt\/tub_xtgrnyznjspm2vxf_lepv7o.png","https:\/\/habrastorage.org\/webt\/l2\/pl\/lz\/l2pllz5jvccjhbz0zzxcitkrmsk.png","https:\/\/habrastorage.org\/webt\/x9\/2-\/5s\/x92-5sqis-vgly1ccyh0gjt2mxy.png","https:\/\/habrastorage.org\/webt\/ge\/w9\/kz\/gew9kzazsmr5pwee16cuyor6n2w.png","https:\/\/habrastorage.org\/webt\/2w\/xu\/eb\/2wxuebmewhsjvjbr_9taaq5zhn4.png","https:\/\/habrastorage.org\/webt\/x9\/8i\/a-\/x98ia-rs9owg6hl2qqkfjpza-yg.png","https:\/\/habrastorage.org\/webt\/c9\/ym\/lq\/c9ymlqxv89qg1oohi-lnhknyedg.png","https:\/\/habrastorage.org\/webt\/fl\/r1\/kv\/flr1kvyks_o2kdciv4pekiwtbiy.png","https:\/\/habrastorage.org\/webt\/im\/aq\/aj\/imaqajo2oi-qoyb--oja3i2fnyy.png","https:\/\/habrastorage.org\/webt\/xl\/wg\/7y\/xlwg7yv4du2k8ktumnmdltwci78.png","https:\/\/habrastorage.org\/webt\/tf\/6w\/c0\/tf6wc0eulg65fu-dy64mmkjyr4g.png","https:\/\/habrastorage.org\/webt\/p-\/2l\/l5\/p-2ll5-sxmfivl2136kopu1oipi.png","https:\/\/habrastorage.org\/webt\/ri\/kn\/r9\/riknr9odspcwgtmywqapeq1htmi.png","https:\/\/habrastorage.org\/webt\/wh\/bl\/fv\/whblfvj4lnbmdryfev1fypctp74.png","https:\/\/habrastorage.org\/webt\/zx\/bx\/gi\/zxbxgimmd3xniduuuw0spq0vg1o.png","https:\/\/habrastorage.org\/webt\/kq\/b0\/-1\/kqb0-1ox3sevtkje8qnb7ekp1is.png","https:\/\/habrastorage.org\/webt\/6a\/fd\/mi\/6afdmitt6iid3yqd6cmdgq8_lkq.png","https:\/\/habrastorage.org\/webt\/cx\/1d\/g3\/cx1dg33kkvufonoxpwrrpmmabza.png","https:\/\/habrastorage.org\/webt\/w4\/bj\/po\/w4bjpoxgbdggewegwtrg1ao9mpi.png","https:\/\/habrastorage.org\/webt\/cn\/hr\/41\/cnhr41tyx4sf0c0skbjqrgbyb90.png","https:\/\/habrastorage.org\/webt\/wv\/yd\/yj\/wvydyj9d_mfo3xztj9elcbvpdaa.png","https:\/\/habrastorage.org\/webt\/xf\/2j\/lc\/xf2jlclf52i3oi3nsxdksth-xpe.png","https:\/\/habrastorage.org\/webt\/bn\/ck\/ss\/bnckssznjbmcrm7v4zh7yhgoltw.png","https:\/\/habrastorage.org\/webt\/cc\/hr\/az\/cchrazzrhareykxd78meljitrso.png"]}</script>
  <script src="//www.googletagservices.com/tag/js/gpt.js" async></script>
  <style>.grecaptcha-badge{visibility: hidden;}</style>
  <meta name="habr-version" content="2.49.0">
  
  <meta data-vue-meta="ssr" property="fb:app_id" content="444736788986613"><meta data-vue-meta="ssr" property="fb:pages" content="472597926099084"><meta data-vue-meta="ssr" name="twitter:card" content="summary_large_image"><meta data-vue-meta="ssr" name="twitter:site" content="@habr_eng"><meta data-vue-meta="ssr" property="og:title" content="Юрий Бушмелев «Карта граблей на поле сбора и доставки логов» — расшифровка доклада" data-vmid="og:title"><meta data-vue-meta="ssr" name="twitter:title" content="Юрий Бушмелев «Карта граблей на поле сбора и доставки логов» — расшифровка доклада" data-vmid="twitter:title"><meta data-vue-meta="ssr" name="aiturec:title" content="Юрий Бушмелев «Карта граблей на поле сбора и доставки логов» — расшифровка доклада" data-vmid="aiturec:title"><meta data-vue-meta="ssr" name="description" content="Логи — важная часть системы, позволяющая понять, что она работает (либо не работает), как ожидается. В условиях микросервисной архитектуры работа с логами становится отдельной дисциплиной специальной..." data-vmid="description"><meta data-vue-meta="ssr" itemprop="description" content="Логи — важная часть системы, позволяющая понять, что она работает (либо не работает), как ожидается. В условиях микросервисной архитектуры работа с логами становится отдельной дисциплиной специальной..." data-vmid="description:itemprop"><meta data-vue-meta="ssr" property="og:description" content="Логи — важная часть системы, позволяющая понять, что она работает (либо не работает), как ожидается. В условиях микросервисной архитектуры работа с логами становится отдельной дисциплиной специальной..." data-vmid="og:description"><meta data-vue-meta="ssr" name="twitter:description" content="Логи — важная часть системы, позволяющая понять, что она работает (либо не работает), как ожидается. В условиях микросервисной архитектуры работа с логами становится отдельной дисциплиной специальной..." data-vmid="twitter:description"><meta data-vue-meta="ssr" property="aiturec:description" content="Логи — важная часть системы, позволяющая понять, что она работает (либо не работает), как ожидается. В условиях микросервисной архитектуры работа с логами становится отдельной дисциплиной специальной..." data-vmid="aiturec:description"><meta data-vue-meta="ssr" itemprop="image" content="https://habr.com/share/publication/450098/3a4ab30ede0a7cb85b099081b994322c/" data-vmid="image:itemprop"><meta data-vue-meta="ssr" property="og:image" content="https://habr.com/share/publication/450098/3a4ab30ede0a7cb85b099081b994322c/" data-vmid="og:image"><meta data-vue-meta="ssr" property="aiturec:image" content="https://habr.com/share/publication/450098/3a4ab30ede0a7cb85b099081b994322c/" data-vmid="aiturec:image"><meta data-vue-meta="ssr" name="twitter:image" content="https://habr.com/share/publication/450098/3a4ab30ede0a7cb85b099081b994322c/" data-vmid="twitter:image"><meta data-vue-meta="ssr" property="vk:image" content="https://habr.com/share/publication/450098/3a4ab30ede0a7cb85b099081b994322c/" data-vmid="vk:image"><meta data-vue-meta="ssr" property="aiturec:item_id" content="450098" data-vmid="aiturec:item_id"><meta data-vue-meta="ssr" property="aiturec:datetime" content="2019-04-30T06:54:36.000Z" data-vmid="aiturec:datetime"><meta data-vue-meta="ssr" property="og:type" content="article" data-vmid="og:type"><meta data-vue-meta="ssr" property="og:locale" content="ru_RU" data-vmid="og:locale"><meta data-vue-meta="ssr" property="og:image:width" content="1200" data-vmid="og:image:width"><meta data-vue-meta="ssr" property="og:image:height" content="630" data-vmid="og:image:height">
  <link data-vue-meta="ssr" href="https://habr.com/ru/rss/post/450098/?fl=ru" type="application/rss+xml" title="" rel="alternate" name="rss"><link data-vue-meta="ssr" href="https://habr.com/ru/post/450098/" rel="canonical" data-vmid="canonical"><link data-vue-meta="ssr" data-vmid="hreflang"><link data-vue-meta="ssr" image_src="image" href="https://habr.com/share/publication/450098/3a4ab30ede0a7cb85b099081b994322c/" data-vmid="image:href">
  <meta name="apple-mobile-web-app-status-bar-style" content="#303b44">
  <meta name="msapplication-TileColor" content="#629FBC">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="16x16"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-16.png"
  >
  <link
    rel="shortcut icon"
    type="image/png"
    sizes="32x32"
    href="https://assets.habr.com/habr-web/img/favicons/favicon-32.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="76x76"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-76.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="120x120"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="152x152"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-152.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="180x180"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-180.png"
  >
  <link
    rel="apple-touch-icon"
    type="image/png"
    sizes="256x256"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-256.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1136x640.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2436x1125.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1792x828.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_828x1792.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1334x750.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2208x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 812px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1125x2436.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 736px) and (-webkit-device-pixel-ratio: 3) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1242x2208.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2732x2048.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 414px) and (device-height: 896px) and (-webkit-device-pixel-ratio: 3) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2688x1242.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2224x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 375px) and (device-height: 667px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_750x1334.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 1024px) and (device-height: 1366px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x2732.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2388x1668.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1112px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2224.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 320px) and (device-height: 568px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_640x1136.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 834px) and (device-height: 1194px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1668x2388.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: landscape)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_2048x1536.png"
  >
  <link
    rel="apple-touch-startup-image"
    media="screen and (device-width: 768px) and (device-height: 1024px) and (-webkit-device-pixel-ratio: 2) and (orientation: portrait)"
    href="https://assets.habr.com/habr-web/img/splashes/splash_1536x2048.png"
  >
  <link
    rel="mask-icon"
    color="#77a2b6"
    href="https://assets.habr.com/habr-web/img/favicons/apple-touch-icon-120.svg"
  >
  <link
    crossorigin="use-credentials"
    href="/manifest.webmanifest"
    rel="manifest"
  >
</head>
<body>


<div id="app" data-server-rendered="true" data-async-called="true"><div class="tm-layout__wrapper"><!----> <div></div> <!----> <header class="tm-header"><div class="tm-page-width"><div class="tm-header__container"><!----> <span class="tm-header__logo-wrap"><a href="/ru/" class="tm-header__logo tm-header__logo_ru"><svg height="16" width="16" class="tm-svg-img tm-header__icon"><title>Хабр</title> <use xlink:href="/img/habr-logo-ru.svg#logo"></use></svg></a> <span class="tm-header__beta-sign" style="display:none;">β</span></span> <div class="tm-dropdown tm-header__projects"><div class="tm-dropdown__head"><button class="tm-header__dropdown-toggle"><svg height="16" width="16" class="tm-svg-img tm-header__icon tm-header__icon_dropdown"><title>Открыть список</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#arrow-down"></use></svg></button></div> <!----></div> <a href="/ru/sandbox/start/" class="tm-header__become-author-btn">
            Как стать автором
          </a> <div class="tm-feature tm-header__feature tm-feature_variant-inline"><!----></div> <!----> <!----></div></div></header> <div class="tm-layout"><div class="tm-page-progress-bar"></div> <div data-menu-sticky="true" class="tm-base-layout__header tm-base-layout__header_is-sticky"><div class="tm-page-width"><div class="tm-base-layout__header-wrapper"><div class="tm-main-menu"><div class="tm-main-menu__section"><nav class="tm-main-menu__section-content"><!----> <a href="/ru/all/" class="tm-main-menu__item">
        Все потоки
      </a> <a href="/ru/flows/develop/" class="tm-main-menu__item">
          Разработка
        </a><a href="/ru/flows/admin/" class="tm-main-menu__item">
          Администрирование
        </a><a href="/ru/flows/design/" class="tm-main-menu__item">
          Дизайн
        </a><a href="/ru/flows/management/" class="tm-main-menu__item">
          Менеджмент
        </a><a href="/ru/flows/marketing/" class="tm-main-menu__item">
          Маркетинг
        </a><a href="/ru/flows/popsci/" class="tm-main-menu__item">
          Научпоп
        </a></nav></div></div> <div class="tm-header-user-menu tm-base-layout__user-menu"><a href="/ru/search/" class="tm-header-user-menu__item tm-header-user-menu__search"><svg height="24" width="24" class="tm-svg-img tm-header-user-menu__icon tm-header-user-menu__icon_search tm-header-user-menu__icon_dark"><title>Поиск</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#search"></use></svg></a> <!----> <!----> <!----> <div class="tm-header-user-menu__item tm-header-user-menu__user_desktop"><div class="tm-dropdown"><div class="tm-dropdown__head"><svg height="24" width="24" data-test-id="menu-toggle-guest" class="tm-svg-img tm-header-user-menu__icon"><title>Профиль</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#header-user"></use></svg> <!----></div> <!----></div> <!----></div> <!----></div></div></div></div> <!----> <div class="tm-page-width"></div> <main class="tm-layout__container"><div hl="ru" data-async-called="true" class="tm-page"><div class="tm-page-width"><!----> <div class="tm-page__wrapper"><div class="tm-page__main tm-page__main_has-sidebar"><div class="pull-down"><div class="pull-down__header" style="height:0px;"><div class="pull-down__content" style="bottom:10px;"><svg height="24" width="24" class="tm-svg-img pull-down__arrow"><title>Обновить</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#pull-arrow"></use></svg></div></div> <div class="tm-article-presenter"> <div class="tm-article-presenter__body"><div class="tm-misprint-area"><div class="tm-misprint-area__wrapper"><article class="tm-article-presenter__content tm-article-presenter__content_narrow"><div class="tm-article-presenter__header"> <div class="tm-article-snippet tm-article-presenter__snippet"><div class="tm-article-snippet__meta-container"><div class="tm-article-snippet__meta"><span class="tm-user-info tm-article-snippet__author"><a href="/ru/users/gecube/" title="gecube" class="tm-user-info__userpic"><div class="tm-entity-image"><img alt="" height="24" loading="lazy" src="//habrastorage.org/r/w32/getpro/habr/avatars/758/e87/53e/758e8753ee221a40fefb2834b63aa875.jpg" width="24" class="tm-entity-image__pic"></div></a> <span class="tm-user-info__user"><a href="/ru/users/gecube/" class="tm-user-info__username">
      gecube
    </a> </span></span> <span class="tm-article-snippet__datetime-published"><time datetime="2019-04-30T06:54:36.000Z" title="2019-04-30, 09:54">30  апреля  2019 в 09:54</time></span></div> <!----></div> <h1 lang="ru" class="tm-article-snippet__title tm-article-snippet__title_h1"><span>Юрий Бушмелев «Карта граблей на поле сбора и доставки логов» — расшифровка доклада</span></h1> <div class="tm-article-snippet__hubs"><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/sys_admin/" class="tm-article-snippet__hubs-item-link"><span>Системное администрирование</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/s_admin/" class="tm-article-snippet__hubs-item-link"><span>Серверное администрирование</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span><span class="tm-article-snippet__hubs-item"><a href="/ru/hub/devops/" class="tm-article-snippet__hubs-item-link"><span>DevOps</span> <span title="Профильный хаб" class="tm-article-snippet__profiled-hub">*</span></a></span></div> <!----> <!----> <!----></div></div> <!----> <div data-gallery-root="" lang="ru" class="tm-article-body"><div id="post-content-body" class="article-formatted-body article-formatted-body_version-1"><div xmlns="http://www.w3.org/1999/xhtml"><p>Логи — важная часть системы, позволяющая понять, что она работает (либо не работает), как ожидается. В условиях микросервисной архитектуры работа с логами становится отдельной дисциплиной специальной олимпиады. Нужно решить сразу кучу вопросов:</p><br/>
<ul>
<li>как писать логи из приложения;</li>
<li>куда писать логи;</li>
<li>как доставлять логи для хранения и обработки;</li>
<li>как обрабатывать и хранить логи.</li>
</ul><br/>
<p>Применение популярных ныне технологий контейнеризации добавляет песочка поверх граблей на поле вариантов решения задачи.</p><br/>
<p>Как раз об этом расшифровка доклада Юрия Бушмелева "Карта граблей на поле сбора и доставки логов" </p><br/>
<div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.2493%;"><div class="tm-iframe_temp" data-src="https://www.youtube.com/embed/NAeedJv-S3I?rel=0&amp;showinfo=1&amp;hl=en-US" data-style="border: 0; top: 0; left: 0; width: 100%; height: 100%; position: absolute;" id="" width=""></div></div></div></div><br/>
<p>Кому интересно, прошу под кат.</p><a name="habracut"></a><br/>
<p>Меня зовут Юрий Бушмелев. Я работаю в Lazada. Я сегодня буду рассказывать про то, как мы делали наши логи, как мы их собирали, и что мы туда пишем. </p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/_9/te/o5/_9teo5cvnhsihs4lyyyc_8pcx-m.png"/></p><br/>
<p>Откуда мы? Кто мы такие? Lazada — это интернет-магазин №1 в шести странах Юго-Восточной Азии. Все эти страны у нас распределены по дата-центрам. Всего дата-центров сейчас 4. Почему это важно? Потому что некоторые решения были обусловлены тем, что между центрами есть очень слабый линк. У нас микросервисная архитектура. Я удивился, обнаружив, что у нас уже 80 микросервисов. Когда я начинал задачу с логами, их было всего 20. Плюс есть довольно большой кусок PHP legacy, с которым тоже приходится жить и мириться. Все это генерирует нам на данный момент более 6 миллионов сообщений в минуту по системе в целом. Дальше я буду показывать, как мы с этим пытаемся жить, и почему это так.</p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/gy/fj/du/gyfjduafaipfx1ay5efm8xpwtdc.png"/></p><br/>
<p>С этими 6 миллионами сообщений надо как-то жить. Что мы с ними должны сделать? 6 миллионов сообщений, которые надо:</p><br/>
<ul>
<li>отправить из приложения</li>
<li>принять для доставки</li>
<li>доставить для анализа и хранения.</li>
<li>проанализировать</li>
<li>как-то хранить.</li>
</ul><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/vq/kr/yt/vqkrytwk4c_gjs9fza8_zn9hanu.png"/></p><br/>
<p>Когда появилось три миллиона сообщений, у меня был примерно такой же вид. Потому что мы начинали с каких-то копеек. Понятно, что туда пишутся логи приложений. Например, не смог подключиться к базе данных, смог подключиться к базе данных, но не смог что-то прочитать. Но кроме этого, каждый наш микросервис пишет еще и access-лог. Каждый запрос, прилетевший на микросервис, падает в лог. Зачем мы это делаем? Разработчики хотят иметь возможность трейсинга. В каждом access-логе лежит поле traceid, по которому дальше специальный интерфейс раскручивает всю цепочку и красиво показывает трейс. Трейс показывает, как проходил запрос, и это помогает нашим разработчикам быстрее справляться со всякой неопознанной фигней.</p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/me/fd/7d/mefd7deeshbhsvsjb8n7dh81ok4.png"/></p><br/>
<p>Как с этим жить? Сейчас я вкратце расскажу поле вариантов — как вообще эта проблема решается. Как решать задачу сбора, передачи и хранения логов. </p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/0m/f8/4r/0mf84rxvsn0ewrqui_4egxgb2hk.png"/></p><br/>
<p>Как писать из приложения? Понятно, что есть разные способы. В частности, есть best practice, как нам рассказывают модные товарищи. Есть old school в двух видах, как рассказывали деды. Есть другие способы. </p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/le/7-/_n/le7-_n8o7wl8nh4g0qadwz-jucq.png"/></p><br/>
<p>Со сбором логов примерно такая же ситуация. Вариантов решения этой конкретной части не так много. Их уже больше, но ещё не так много. </p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/kn/id/o2/knido22_ecpa0cgvfjzissz3fei.png"/></p><br/>
<p>А вот с доставкой и последующим анализом — количество вариаций начинает взрываться. Описывать каждый вариант сейчас не буду. Думаю, основные варианты на слуху у всех, кто интересовался темой.</p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/qu/zg/z0/quzgz0a21pgjdb0o8ek5d3nxmwc.png"/></p><br/>
<p>Я покажу, как мы делали это в Lazada, и как собственно все это начиналось. </p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/tu/b_/xt/tub_xtgrnyznjspm2vxf_lepv7o.png"/></p><br/>
<p>Год назад я пришёл в Лазаду, и меня отправили на проект про логи. Там было примерно вот так. Лог из приложения писался в stdout и stderr. Все сделали по-модному. Но дальше разработчики это выкинули из стандартных потоков, а дальше там как-нибудь специалисты по инфраструктуре разберутся. Между инфраструктурными специалистами и разработчиками есть еще релизеры, которые сказали: «эээ… ну ладно, давайте их в файл завернем просто shell-ом, и все». А поскольку все это в контейнере, то завернули прям в самом контейнере, промапили внутрь каталог и положили это туда. Думаю, что всем примерно очевидно, что из этого получилось.</p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/l2/pl/lz/l2pllz5jvccjhbz0zzxcitkrmsk.png"/></p><br/>
<p>Посмотрим пока чуть подальше. Как мы эти логи доставляли. Кто-то выбрал td-agent, который на самом деле fluentd, но не совсем fluentd. Я так и не понял отношения этих двух проектов, но они, вроде бы, об одном и том же. И вот этот вот fluentd, написанный на Ruby, читал файлы логов, парсил их в JSON по каким-то регуляркам. Потом их отправлял в Kafka. Причем в Kafka на каждую API у нас было 4 отдельных топика. Почему 4? Потому что есть live, есть staging, и потому что есть stdout и stderr. Разработчики их плодят, а инфраструктурщики должны их создавать в Kafka. Причем, Kafka контролировалась другим отделом. Поэтому надо было создавать тикет, чтобы они создали там 4 топика на каждый api. Все про это забывали. В общем был треш и угар. </p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/x9/2-/5s/x92-5sqis-vgly1ccyh0gjt2mxy.png"/></p><br/>
<p>Что мы дальше с этим делали? Мы отправляли это в кафку. Дальше из кафки половина логов улетала в Logstash. Другая половина логов делилась. Часть улетала в один Graylog, часть – в другой Graylog. В итоге всё это улетало в один кластер Elasticsearch. То есть, весь этот бардак падал в итоге туда. Так делать не надо!</p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/ge/w9/kz/gew9kzazsmr5pwee16cuyor6n2w.png"/></p><br/>
<p>Вот так это выглядит, если отдаленно сверху посмотреть. Не надо так делать! Здесь вот цифрами сразу отмечены проблемные места. Их на самом деле больше, но 6 — это вот прям совсем проблемные, с которыми надо что то делать. Про них я сейчас отдельно расскажу. </p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/2w/xu/eb/2wxuebmewhsjvjbr_9taaq5zhn4.png"/></p><br/>
<p>Вот здесь (1,2,3) у нас пишутся файлы и, соответственно, здесь сразу три грабли. </p><br/>
<p>Первое (1) — это нам надо их куда-то писать. Не всегда хотелось бы давать API возможность писать прямо в файл. Желательно, чтобы API была изолирована в контейнере, а еще лучше – чтобы она была read-only. Я — сисадмин, поэтому у меня немного альтернативный взгляд на эти вещи.</p><br/>
<p>Второй момент (2,3) — у нас много запросов приходит в API. API пишет много данных в файл. Файлы растут. Нам их надо ротировать. Потому что иначе там никаких дисков не напасешься. Ротировать их плохо, потому что они сделаны редиректом через shell в каталог. Мы никак не можем его отротировать. Нельзя сказать приложению, чтобы оно переоткрыло дескрипторы. Потому что разработчики на тебя посмотрят как на дурака: «Какие дескрипторы? Мы вообще в stdout пишем». Инфраструктурщики сделали copytruncate в logrotate, который делает просто копию файла и транкейтит оригинал. Соответственно, между этими процессами копирования обычно и кончается место на диске.</p><br/>
<p>(4) У нас были разные форматы были в разных API. Они немножко отличались, но regexp надо было писать разные. Поскольку всё это управлялось Puppet, то там была большая вязанка классов со своими тараканами. Плюс еще td-agent большую часть времени мог есть память, тупить, он мог просто делать вид, что он работает, и ничего не делать. Снаружи понять, что он ничего не делает было невозможно. В лучшем случае он упадет, и его кто-нибудь поднимет потом. Точнее, прилетит alert, и кто-нибудь пойдет руками переподнимет. </p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/x9/8i/a-/x98ia-rs9owg6hl2qqkfjpza-yg.png"/></p><br/>
<p>(6) И самый трэш и угар — это был elasticsearch. Потому что, это была старая версия. Потому что, у нас не было выделенных мастеров на тот момент. У нас были разнородные логи, у которых поля могли пересекаться. Разные логи разных приложений могли писаться с одинаковыми названиями полей, но при этом внутри могли быть разные данные. То есть, один лог приходит с Integer в поле, например, level. Другой лог приходит со String в поле level. В отсутствие статического маппинга получается такая замечательная вещь. Если после ротации индекса в elasticsearch первым прилетело сообщение со строкой, то мы живем нормально. А если вот первым прилетело с Integer, то все последующие сообщения, которые прилетели со String, просто отбрасываются. Потому что не совпадает тип поля.</p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/c9/ym/lq/c9ymlqxv89qg1oohi-lnhknyedg.png"/></p><br/>
<p>Мы начали задаваться вот этими вопросами. Мы решили не искать виноватых.</p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/fl/r1/kv/flr1kvyks_o2kdciv4pekiwtbiy.png"/></p><br/>
<p>А вот что-то делать надо! Очевидная вещь — надо завести стандарты. Некоторые стандарты у нас уже были. Некоторые мы завели чуть позже. К счастью, единый формат логов для всех API уже утвердили на тот момент. Он прописан прямо в стандарты взаимодействия сервисов. Соответственно, те, кто хочет получать логи, должны писать их в этом формате. Если кто-то не пишет логи в этом формате, значит, мы ничего не гарантируем. </p><br/>
<p>Далее, хотелось бы завести единый стандарт на способы записи, доставки и сбора логов. Собственно, куда их писать, и чем их доставлять. Идеальная ситуация — это когда в проектах используется одна и та же библиотека. Вот есть отдельная библиотека логирования для Go, есть отдельный библиотека для PHP. Все кто у нас есть — все должны их использовать. На данный момент я бы сказал, что процентов на 80 у нас это получается. Но некоторые продолжают есть кактусы.</p><br/>
<p>И вот там вот (на слайде) еле-еле начинает проступать «SLA на доставку логов». Его пока нет, но мы над этим работаем. Потому что это очень удобно, когда инфра говорит, что если вы пишете в таком-то формате в такое-то место и не более N сообщений в секунду, то мы это с вероятностью такой-то доставим туда-то. Это снимает кучу головной боли. Если SLA есть, то это прямо замечательно!</p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/im/aq/aj/imaqajo2oi-qoyb--oja3i2fnyy.png"/></p><br/>
<p>Как мы начали решать проблему? Основная грабля была с td-agent. Было непонятно, куда у нас деваются логи. Доставляются ли они? Собираются ли они? Где они вообще? Поэтому, первым пунктом было решено заменить td-agent. Варианты, на что его заменить, вкратце я здесь набросал.</p><br/>
<p>Fluentd. Во-первых, я с ним сталкивался на предыдущей работе, и он там тоже периодически падал. Во-вторых, это тоже самое, только в профиль. </p><br/>
<p>Filebeat. Чем он был удобен для нас? Тем, что он на Go, а у нас большая экспертиза в Go. Cоответственно, если что, мы могли его под себя как-то дописать. Поэтому мы его и не взяли. Чтобы даже соблазна никакого не было начинать его под себя переписывать. </p><br/>
<p>Очевидным решением для сисадмина остаются всякие сислоги вот в таком вот количестве (syslog-ng/rsyslog/nxlog).</p><br/>
<p>Либо написать что-то свое, но мы это отбросили, равно как и filebeat. Если что-то писать, то лучше писать что-то полезное для бизнеса. Для доставки логов лучше взять что-то готовое.</p><br/>
<p>Поэтому выбор фактически свелся к выбору между syslog-ng и rsyslog. Cклонился в сторону rsyslog просто потому, что у нас в Puppet уже были классы для rsyslog, и я не нашел между ними очевидной разницы. Что там syslog, что тут syslog. Да, у кого-то документация хуже, у кого-то лучше. Тот умеет так, а тот — по-другому.</p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/xl/wg/7y/xlwg7yv4du2k8ktumnmdltwci78.png"/></p><br/>
<p>И немножко про rsyslog. Во-первых, он клёвый, потому что у него есть много модулей. У него человеко-понятный RainerScript (современный язык конфигурации). Офигенный бонус, что мы могли его штатными средствами сэмулировать поведение td-agent, и для приложений ничего не поменялось. То есть, мы меняем td-agent на rsyslog, а все остальное пока не трогаем. И сразу получаем работающую доставку. Далее, mmnormalize — это офигенная штука в rsyslog. Она позволяет парсить логи, но не с помощью Grok и regexp. Она делает abstract syntax tree. Она парсит логи примерно, как компилятор парсит исходники. Это позволяет работать очень быстро, жрать мало CPU, и, вообще, прям очень клёвая штука. Есть куча других бонусов. Я о них не буду останавливаться.</p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/tf/6w/c0/tf6wc0eulg65fu-dy64mmkjyr4g.png"/></p><br/>
<p>У rsyslog есть ещё куча недостатков. Они примерно такие же, как и бонусы. Основные проблемы — надо уметь его готовить, и надо подбирать версию.</p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/p-/2l/l5/p-2ll5-sxmfivl2136kopu1oipi.png"/></p><br/>
<p>Мы решили что будем писать логи в unix socket. Причем не в /dev/log, потому что там у нас каша из системных логов, там journald в этом pipeline. Поэтому давайте писать в кастомный сокет. Мы его прицепим к отдельному ruleset. Не будем ничего мешать. Будет все прозрачно и понятно. Так мы собственно и сделали. Каталог с этими сокетами стандартизирован и пробрасывается во все контейнеры. Контейнеры могут видеть нужный им socket, открывать и писать него. </p><br/>
<p>Почему не файл? Потому что все читали <a href="https://habr.com/ru/company/badoo/blog/280606/">статью про Бадушечку</a>, которая пыталась пробросить файл в docker, и обнаруживалось, что после рестарта rsyslog меняется file descriptor, и docker теряет этот файл. Он держит открытым что-то другое, но уже не тот сокет куда пишут. Мы решили, что мы обойдем эту проблему, и, заодно, обойдем проблему блокировки.</p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/ri/kn/r9/riknr9odspcwgtmywqapeq1htmi.png"/></p><br/>
<p>Rsyslog делает действия указанные на слайде и отправляет логи либо в релей, либо в Kafka. Kafka соответствует старому способу. Релей — это я попытался использовать чисто rsyslog для доставки логов. Без Message Queue, стандартными средствами rsyslog. В принципе, это работает.</p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/wh/bl/fv/whblfvj4lnbmdryfev1fypctp74.png"/></p><br/>
<p>Но есть нюансы с тем, как запихивать их потом в эту часть (Logstash/Graylog/ES). Эта часть (rsyslog-rsyslog) используется между датацентрами. Здесь compressed tcp link, который позволяет сэкономить bandwidth и, соответственно, как-то увеличить вероятность того, что мы получим какие-то логи из другого датацентра в условиях, когда канал забит. Потому что, нас есть Индонезия, в которой все плохо. Вот там эта постоянная проблема.</p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/zx/bx/gi/zxbxgimmd3xniduuuw0spq0vg1o.png"/></p><br/>
<p>Мы задумались над тем как нам собственно промониторить, с какой вероятностью логи, которые мы записали из приложения, доезжают до того конца? Мы решили завести метрики. У rsyslog есть свой модуль сбора статистики, в котором есть какие-то счетчики. Например, он может показать вам размер очереди, или сколько сообщений пришло в такой-то action. Из них уже можно что-то взять. Плюс, у него есть кастомные счетчики, которые можно настроить, и он будет вам показывать, например, количество сообщений, который записало какое-то API. Далее, я написал rsyslog_exporter на Python, и мы все это отправили в Prometheus и построили графики. Метрики Graylog очень хотелось, но пока мы не успели их настроить.</p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/kq/b0/-1/kqb0-1ox3sevtkje8qnb7ekp1is.png"/></p><br/>
<p>С чем возникли проблемы? Проблемы возникли с тем, что у нас обнаружилось (ВНЕЗАПНО!), что наши Live API пишут по 50к сообщений в секунду. Это только Live API без staging. А Graylog нам показывает только 12 тысяч сообщений в секунду. И возник резонный вопрос, а где остатки-то? Из чего мы сделали вывод, что Graylog просто не справляется. Посмотрели, и, действительно, Graylog с Elasticsearch не осиливали этот поток.</p><br/>
<p>Далее, другие открытия, которые мы сделали в процессе.</p><br/>
<p>Запись в socket блокируются. Как это случилось? Когда я использовал rsyslog для доставки, в какой-то момент у нас сломался канал между датацентрами. Встала доставка в одном месте, встала доставка другом месте. Все это докатилась до машины с API, которые пишут в сокет rsyslog. Там заполнилась очередь. Потом заполнилась очередь на запись в unix socket, которая по умолчанию 128 пакетов. И следующий write() в приложении блокируется. Когда мы смотрели в библиотечку, которой пользуемся в приложениях на Go, там было написано, что запись в сокет происходит в неблокирующемся режиме. Мы были уверены, что ничего не блокируется. Потому что мы читали <a href="https://habr.com/ru/company/badoo/blog/280606/">статью про Бадушечку</a>, которая про это написала. Но есть момент. Вокруг этого вызова был еще бесконечный цикл, в котором постоянно происходила попытка запихать сообщение в сокет. Вот его мы не заметили. Пришлось переписать библиотеку. С тех пор она несколько раз менялась, но сейчас мы избавились от блокировок во всех подсистемах. Поэтому, можно останавливать rsyslog, и ничего не упадет.</p><br/>
<p>Нужно мониторить размер очередей, что помогает не наступить на эти грабли. Во-первых, мы можем мониторить, когда мы начинаем терять сообщения. Во-вторых, можем мониторить что у нас в принципе проблемы с доставкой.</p><br/>
<p>И еще неприятный момент — амплификация в 10 раз в микросервисной архитектуре — это очень легко. У нас входящих запросов не так много, но из-за графа, по которому бегают эти сообщения дальше, из-за access-логов, мы реально увеличиваем нагрузку по логам примерно раз в десять. Я к сожалению не успел посчитать точные цифры, но микросервисы — они такие. Это надо иметь в виду. Получается, что на данный момент подсистема сбора логов — самая нагруженная в Lazada. </p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/6a/fd/mi/6afdmitt6iid3yqd6cmdgq8_lkq.png"/></p><br/>
<p>Как решить проблему elasticsearch? Если надо быстро получить логи в одном месте, чтобы не бегать по всем машинам, и не собирать их там, используйте файловое хранилище. Это гарантированно работает. Оно делается из любого сервера. Надо просто натыкать туда дисков и поставить syslog. После этого у вас гарантированно в одном месте все логи есть. Дальше уже можно будет неспешно настраивать elasticsearch, graylog, что-нибудь еще. Но у вас уже будут все логи, и, причем, вы их можете хранить, насколько хватает дисковых массивов.</p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/cx/1d/g3/cx1dg33kkvufonoxpwrrpmmabza.png"/></p><br/>
<p>На момент моего доклада схема стала выглядеть вот так. В файл мы практически перестали писать. Сейчас, скорее всего, отлючим остатки. На локальных машинах, на которых запущены API, в файлы мы писать перестанем. Во-первых, есть файловое хранилище, которое работает очень хорошо. Во-вторых, на этих машинах постоянно кончается место, надо его постоянно мониторить.</p><br/>
<p>Вот эта часть с Logstash и Graylog, она реально парит. Поэтому надо от нее избавиться. Надо выбрать что-то одно.</p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/w4/bj/po/w4bjpoxgbdggewegwtrg1ao9mpi.png"/></p><br/>
<p>Мы решили выкинуть Logstash и Kibana. Потому что у нас есть отдел безопасности. Какая связь? Связь в том что Kibana без X-Pack и без Shield не позволяет разграничить права доступа к логам. Поэтому взяли Graylog. В нем все это есть. Он мне не нравится, но он работает. Мы купили нового железа, поставили там свежий Graylog и перенесли все логи со строгими форматами в отдельный Graylog. Мы решили проблему с разными типами одинаковых полей организационно.</p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/cn/hr/41/cnhr41tyx4sf0c0skbjqrgbyb90.png"/></p><br/>
<p>Что собственно в новый Graylog входит. Мы просто записали все в докер. Взяли кучу серверов, раскатали три инстанса Kafka, 7 серверов Graylog версии 2.3 (потому что хотелось Elasticsearch версии 5). Все это на рейдах из HDD подняли. Увидели indexing rate до 100 тысяч сообщений в секунду. Увидели цифру что 140 терабайт данных в неделю. </p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/wv/yd/yj/wvydyj9d_mfo3xztj9elcbvpdaa.png"/></p><br/>
<p>И опять грабли! У нас грядут две распродажи. Мы переехали за 6 миллионов сообщений. У нас Graylog не успевает прожевывать. Как-то надо опять выживать. </p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/xf/2j/lc/xf2jlclf52i3oi3nsxdksth-xpe.png"/></p><br/>
<p>Выжили мы вот так. Добавили еще немножко серверов и SSD. На данный момент мы живем вот таким способом. Сейчас мы прожёвываем уже 160к сообщений в секунду. Мы еще не уперлись в лимит, поэтому пока непонятно, сколько мы реально сможем вытянуть из этого. </p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/bn/ck/ss/bnckssznjbmcrm7v4zh7yhgoltw.png"/></p><br/>
<p>Вот такие у нас планы на будущее. Из них, реально, самое важное, наверное, high availability. У нас его пока нет. Несколько машин настроены одинаково, но едет пока все через одну машину. Надо потратить время, чтобы настроить failover между ними.</p><br/>
<p>Собрать метрики с Graylog.</p><br/>
<p>Сделать rate limit чтобы у нас одна, сошедшая с ума API, не убивала нам bandwidth и все остальное.</p><br/>
<p>И наконец, подписать какой-то SLA c разработчиками, что мы можем обслужить вот столько. Если вы пишете больше, то извините.</p><br/>
<p>И написать документацию.</p><br/>
<p><img src="/img/image-loader.svg" data-src="https://habrastorage.org/webt/cc/hr/az/cchrazzrhareykxd78meljitrso.png"/></p><br/>
<p>Кратенько, итоги всего, что мы пережили. Во-первых, стандарты. Во-вторых, syslog — торт. В-третьих, rsyslog работает именно вот так, как написано на слайде. И давайте перейдем к вопросам.</p><br/>
<p><strong>Вопросы</strong>.</p><br/>
<p><strong>Вопрос</strong>: Почему все-таки решили не брать… (filebeat?)</p><br/>
<p><strong>Ответ</strong>: Надо писать в файл. Очень не хотелось. Когда у тебя API пишет тысячи сообщений в секунду, ты даже если раз в час будешь ротировать, то это все равно не вариант. Можно писать в pipe. На что меня разработчики спросили: «А что будет если, процесс в который мы пишем, упадет»? Я просто не нашел, что им ответить, и сказал: «Ну ок, давайте мы не будем так делать».</p><br/>
<p><strong>Вопрос</strong>: Почему вы не пишете логи просто в HDFS?</p><br/>
<p><strong>Ответ</strong>: Это следующий этап. Мы про него подумали самом начале, но, поскольку, в данный момент нет ресурсов этим заниматься, то он у нас висит в long term solution.</p><br/>
<p><strong>Вопрос</strong>: Колоночный формат был бы более подходящий.</p><br/>
<p><strong>Ответ</strong>: Я все понимаю. Мы "за" обеими руками. </p><br/>
<p><strong>Вопрос</strong>: Вы пишете в rsyslog. Там можно и TCP, и UDP. Но если UDP, то тогда как вы гарантируете доставку?</p><br/>
<p><strong>Ответ</strong>: Есть два момента. Первый, я сразу всем говорю, что мы не гарантируем доставку логов. Потому что, когда разработчики приходят и говорят: «А давайте мы туда начнем писать финансовые данные, а вы будете их нам куда-то складывать на случай, если что-то случится», мы им отвечаем «Отлично! Давайте вы начнете блокироваться на записи в сокет, и делать это в транзакциях, чтобы гарантированно вы нам это в сокет положили и убедились, что мы с той стороны это получили.» И в этот момент всем сразу становится не надо. А раз не надо, то какие к нам вопросы? Если вы не хотите гарантировать запись в сокет, то зачем нам гарантировать доставку? Мы делаем best effort. Мы реально стараемся доставить как можно больше и как можно лучше, но мы не даем 100% гарантии. Поэтому не надо писать туда финансовые данные. Для этого есть базы данных с транзакциями.</p><br/>
<p><strong>Вопрос</strong>: Когда API генерирует какое-то сообщение в лог и передает управление микросервисам, то не сталкивались ли вы с проблемой, что сообщения от разных микросервисов приходят в неправильном порядке? Из-за этого возникает путаница.</p><br/>
<p><strong>Ответ</strong>: Это нормально, что они приходят в разном порядке. К этому надо быть готовым. Потому что любая сетевая доставка вам не гарантирует порядок, или надо тратить специально ресурсы на это. Если возьмем файловые хранилища, то каждая API сохраняет логи в свой файл. Вернее там rsyslog раскладывается их по каталогам. У каждого API там есть свои логи, куда можно пойти и посмотреть, и потом по timestamp в этом логе можно их посопоставлять. Если они идут смотреть в Graylog, то там они отсортируется по timestamp. Там всё будет хорошо.</p><br/>
<p><strong>Вопрос</strong>: Timestamp может отличаться на миллисекунды.</p><br/>
<p><strong>Ответ</strong>: Timestamp генерит сама API. В этом, собственно, вся фишка. У нас есть NTP. API генерит timestamp уже в самом сообщении. Его не rsyslog добавляет.</p><br/>
<p><strong>Вопрос</strong>: Не очень понятно взаимодействие между датацентрами. В рамках датацентра понятно как логи собрали, обработали. Как проиходит взаимодействие между датацентрами? Или каждый датацентр живет своей жизнью?</p><br/>
<p><strong>Ответ</strong>: Почти. У нас каждая страна находится в каком-то одном датацентре. У нас нет на данный момент размазывания, чтобы одна страна была размещена по разным датацентрам. Поэтому не надо их объединять. Внутри каждого центра есть Log Relay. Это Rsyslog сервер. На самом деле две менеджмент машины. Они одинаково настроены. Но пока просто трафик идет через одну из них. Она логи все агрегирует. У нее есть дисковая очередь на всякий случай. Она жмет логи, и отправляет их в центральный датацентр (сингапурский), где дальше они уже отравляются в Graylog. И в каждом датацентре есть свой файловый storage. В случае, если у нас пропала связь, мы имеем все логи там. Они там останутся. Они там будут сохранены.</p><br/>
<p><strong>Вопрос</strong>: При нештатных ситациях оттуда вы получаете логи?</p><br/>
<p><strong>Ответ</strong>: Можно пойти туда (в файловое хранилище) и посмотреть.</p><br/>
<p><strong>Вопрос</strong>: Как вы мониторите то, что вы не теряете логи?</p><br/>
<p><strong>Ответ</strong>: Мы их теряем на самом деле, и мы это мониторим. Мониторинг запустили месяц назад. В библиотеке, которую используют Go API, есть метрики. Она умеет считать, сколько раз она не смогла записать в socket. Там на данный момент есть хитрая эвристика. Там есть буфер. Он пытается записывать из него сообщение в socket. Если буфер переполнится, он начинает их дропать. И считает сколько он их подроппал. Если там начинает переполняться счетчики, мы об этом узнаем. Они сейчас приезжают также в prometheus, и в Grafana можно посмотреть графики. Можно настроить оповещения. Но пока непонятно, кому их отправлять.</p><br/>
<p><strong>Вопрос</strong>: В elasticsearch вы с резервированием храните логи. Сколько у вас реплик?</p><br/>
<p><strong>Ответ</strong>: Одна реплика.</p><br/>
<p><strong>Вопрос</strong>: Это всего одна реплика?</p><br/>
<p><strong>Ответ</strong>: Это мастер и реплика. В двух экземплярах данные хранятся.</p><br/>
<p><strong>Вопрос</strong>: Размер буфера rsyslog вы как-то подкручивали? </p><br/>
<p><strong>Ответ</strong>: Мы пишем дейтаграммы в кастомный unix socket. Это нам сразу же накладывает ограничение 128 килобайт. Мы не можем записать в него больше. Мы прописали это в стандарт. Кто хочет попадать в стореджи, те пишут 128 килобайт. Библиотеки, причем, обрезают, и ставят флаг, что сообщение обрезано. У нас стандарте самого сообщения есть специальные поле, которое показывает было ли оно обрезано при записи или нет. Так что мы имеем возможность отследить и этот момент.</p><br/>
<p><strong>Вопроc</strong>: Пишете ли вы битые JSON? </p><br/>
<p><strong>Ответ</strong>: Битый JSON будет отброшен либо во время relay, потому что слишком большой пакет. Либо будет отброшен Graylog, потому что не сможет JSON распарсить. Но здесь есть нюансы, которые надо фиксить, и они большей частью завязаны на rsyslog. Я уже заполнил туда несколько issue, над которыми надо еще работать.</p><br/>
<p><strong>Вопроc</strong>: Почему Kafka? Пробовали ли RabbitMQ? Не складывается Graylog при таких нагрузках?</p><br/>
<p><strong>Ответ</strong>: У нас с Graylog не складывается. А Graylog у нас складывается. С ним реально проблемно. Он своеобразная штука. И, на самом деле, он не нужен. Я бы предпочел писать из rsyslog напрямую в elasticsearch и смотреть потом Kibana. Но надо утрясти вопрос с безопасниками. Это возможный вариант нашего развития, когда мы выкинем Graylog и будем использовать Kibana. Logstash использовать смысла не будет. Потому что, я могу все это же самое сделать rsyslog. И у него есть модуль для записи в elasticsearch. С Graylog мы пытаемся как-то жить. Мы его даже немножко потюнили. Но там есть еще пространство для улучшений.</p><br/>
<p>Насчет Kafka. Так исторически сложилось. Когда я пришел, она уже была, и в нее уже писали логи. Мы просто подняли наш кластер и переехали в него логами. Мы его менеджим, мы знаем, как он себя чувствует. Насчет RabbitMQ… у нас не складывается c RabbitMQ. А RabbitMQ у нас складывается. У нас продакшне он есть, и с ним были проблемы. Сейчас бы перед распродажей его зашаманили, и он стал нормально работать. Но до этого я был не готов его выпускать в продакшн. Есть еще один момент. Graylog умеет читать версию AMQP 0.9, а rsyslog умеет писать версию AMQP 1.0. И нет ни одного решения, которое посередине умеет и то, и другое. Есть либо то либо другое. Поэтому на данный момент только Kafka. Но там тоже свои нюансы. Потому что omkafka той версии rsyslog, которой мы используем, может потерять вот весь буфер сообщений, которое она выгребла из rsyslog. Пока мы с этим миримся. </p><br/>
<p><strong>Вопроc</strong>: Вы используете Kafka потому, что она у вас в была? Больше ни для каких целей не используется?</p><br/>
<p><strong>Ответ</strong>: Kafka, которая была, используется командой Data Sсience. Это совсем отдельный проект, про который я, к сожалению, ничего сказать не могу. Я не в курсе. Она была в ведении команды Data Sсience. Когда логи заводили решили использовать ее, чтобы не ставить еще и свою. Сейчас мы обновили Graylog, и у нас потерялась совместимость, потому что там старая версия Kafka. Нам пришлось завести свою. Заодно мы избавились от этих четырех топиков на каждый API. Мы сделали один широкий топик на все live, один широкий широкий топик на все staging и просто все туда пуляем. Graylog все это параллельно выгребает.</p><br/>
<p><strong>Вопроc</strong>: Зачем нужно вот это шаманство с сокетами? Пробовали ли использовать log-драйвер syslog для контейнеров.</p><br/>
<p><strong>Ответ</strong>: На тот момент когда мы этим вопросом задавались, с докером у нас отношения были напряженные. Это был docker 1.0 или 0.9. Docker сам по себе был странный. Во-вторых, если в него еще и логи пихать… У меня есть непроверенное подозрение, что он пропускает все логи через себя, через демон докера. Если у нас одно API сходит с ума, то остальные API утыкаются в то, что они не могут отправить stdout и stderr. Я не знаю к чему это приведет. У меня есть подозрение на уровне ощущения, что не надо syslog-драйвер докера вот в этом месте использовать. У нашего отдела функционального тестирование есть свой собственный кластерочек Graylog с логами. Они используют log-драйверы докера и у них там вроде бы даже все хорошо. Но они GELF сразу пишут в Graylog. Мы на тот момент, когда все это затевали, нам надо было чтобы оно просто работало. Возможно потом, когда кто-то придет и скажет, что оно уже сто лет работает нормально, мы попробуем.</p><br/>
<p><strong>Вопроc</strong>: Вы доставку между датацентрами делаете на rsyslog. Почему не на Kafka?</p><br/>
<p><strong>Ответ</strong>: Мы делаем и так, и так на самом деле. По двум причинам. Если канал совсем убитый, то у нас все логи даже в сжатом виде не пролазят него. А кафка позволяет их просто терять в процессе. Мы этим способом избавляемся от залипания вот этих логов. Мы просто используем Kafka в этом случае напрямую. Eсли у нас канал хороший и хочется освободить его, то мы используем их rsyslog. Но на самом деле можно его настроить его так, чтобы он сам дропал то, что не пролезло. На данный момент мы просто где-то используем доставку rsyslog напрямую, где-то Kafka.</p></div></div> <!----> <!----></div> <div class="tm-article-presenter__meta"><div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Теги:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bdevops%5D" class="tm-tags-list__link">devops</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Belasticsearch%5D" class="tm-tags-list__link">elasticsearch</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Brsyslog%5D" class="tm-tags-list__link">rsyslog</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bgraylog%5D" class="tm-tags-list__link">graylog</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5Bkafka%5D" class="tm-tags-list__link">kafka</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D1%81%D0%B1%D0%BE%D1%80%20%D0%BB%D0%BE%D0%B3%D0%BE%D0%B2%5D" class="tm-tags-list__link">сбор логов</a></li><li class="tm-separated-list__item"><a href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=%5B%D0%BB%D0%BE%D0%B3%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5%5D" class="tm-tags-list__link">логирование</a></li></ul></div> <div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Хабы:</span> <ul class="tm-separated-list__list"><li class="tm-separated-list__item"><a href="/ru/hub/sys_admin/" class="tm-hubs-list__link">
    Системное администрирование
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/s_admin/" class="tm-hubs-list__link">
    Серверное администрирование
  </a></li><li class="tm-separated-list__item"><a href="/ru/hub/devops/" class="tm-hubs-list__link">
    DevOps
  </a></li></ul></div></div></article></div> <!----></div> <div class="tm-article-sticky-panel"><div class="tm-data-icons tm-article-sticky-panel__icons"><div class="tm-article-rating tm-data-icons__item"><div class="tm-votes-meter tm-article-rating__votes-switcher"><svg height="16" width="16" class="tm-svg-img tm-votes-meter__icon tm-votes-meter__icon_medium"><title>Всего голосов 10: ↑9 и ↓1</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-rating"></use></svg> <span title="Всего голосов 10: ↑9 и ↓1" class="tm-votes-meter__value tm-votes-meter__value_positive tm-votes-meter__value_medium">+8</span></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----> <span title="Количество просмотров" class="tm-icon-counter tm-data-icons__item"><svg height="16" width="16" class="tm-svg-img tm-icon-counter__icon"><title>Просмотры</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-views"></use></svg> <span class="tm-icon-counter__value">8K</span></span> <button title="Добавить в закладки" type="button" class="bookmarks-button tm-data-icons__item"><span title="Добавить в закладки" class="tm-svg-icon__wrapper bookmarks-button__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Добавить в закладки</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-favorite"></use></svg></span> <span title="Количество пользователей, добавивших публикацию в закладки" class="bookmarks-button__counter">
    52
  </span></button> <!----> <div title="Поделиться" class="tm-sharing tm-data-icons__item"><button type="button" class="tm-sharing__button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="tm-sharing__icon"><path fill="currentColor" d="M10.33.275l9.047 7.572a.2.2 0 010 .306l-9.048 7.572a.2.2 0 01-.328-.153V11c-8 0-9.94 6-9.94 6S-1 5 10 5V.428a.2.2 0 01.328-.153z"></path></svg></button> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> </div></div> <!----> <!----> <div class="tm-article-presenter__footer"><div class="tm-article-blocks"><!----> <section class="tm-block tm-block_spacing-bottom"><!----> <div class="tm-block__body tm-block__body_variant-balanced"><div class="tm-article-author"> <div class="tm-user-card tm-article-author__user-card tm-user-card_variant-article"><div class="tm-user-card__info-container"><div class="tm-user-card__header"><div class="tm-user-card__header-data"><a href="/ru/users/gecube/" class="tm-user-card__userpic tm-user-card__userpic_size-40"><div class="tm-entity-image"><img alt="" src="//habrastorage.org/getpro/habr/avatars/758/e87/53e/758e8753ee221a40fefb2834b63aa875.jpg" class="tm-entity-image__pic"></div></a> <div class="tm-user-card__meta"><div title=" 387 голосов " class="tm-karma tm-user-card__karma"><div class="tm-karma__votes tm-karma__votes_negative">
    -1
  </div> <div class="tm-karma__text">
    Карма
  </div></div> <div title="Рейтинг пользователя" class="tm-rating tm-user-card__rating"><div class="tm-rating__header"> <div class="tm-rating__counter">0.6</div></div> <div class="tm-rating__text">
    Рейтинг
  </div></div></div></div></div> <div class="tm-user-card__info tm-user-card__info_variant-article"><div class="tm-user-card__title tm-user-card__title_variant-article"><!----> <a href="/ru/users/gecube/" class="tm-user-card__nickname tm-user-card__nickname_variant-article">
          @gecube
        </a> <!----></div> <p class="tm-user-card__short-info tm-user-card__short-info_variant-article">Кубернетес, карты, два ствола</p></div></div> <div class="tm-user-card__buttons tm-user-card__buttons_variant-article"><!----> <!----> <!----> <!----> <!----></div></div> <!----></div> <DIV class="v-portal" style="display:none;"></DIV></div> <!----></section> <div class="tm-article-blocks__comments"><div class="tm-article-page-comments"><div class="tm-article-comments-counter-link tm-article-comments-counter-button"><a href="/ru/post/450098/comments/" class="tm-article-comments-counter-link__link tm-article-comments-counter-link__link_button-style"><svg height="16" width="16" class="tm-svg-img tm-article-comments-counter-link__icon tm-article-comments-counter-link__icon_contrasted"><title>Комментарии</title> <use xlink:href="/img/megazord-v24.ce74655c.svg#counter-comments"></use></svg> <span class="tm-article-comments-counter-link__value tm-article-comments-counter-link__value_contrasted">
       Комментарии 13 
    </span></a> <!----></div></div></div> <div class="tm-ad-banner__container tm-page-article__banner"><!----> <div id="articleBottomBanner" class="tm-ad-banner"></div></div> <!----> <!----> <!----> <!----> </div></div></div></div></div> <div class="tm-page__sidebar"><div class="tm-layout-sidebar"><div class="tm-layout-sidebar__ads tm-layout-sidebar__ads_initial"><div class="tm-ad-banner__container tm-layout-sidebar__banner"><!----> <div id="sidebarBanner" class="tm-ad-banner"></div></div></div> <div class="tm-sexy-sidebar tm-sexy-sidebar_initial" style="margin-top:0px;"><!----> <!----></div></div></div></div></div></div></main> <!----></div> <div class="tm-footer-menu"><div class="tm-page-width"><div class="tm-footer-menu__container"><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Ваш аккаунт
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr/?back=/ru/post/450098/&amp;hl=ru" rel="nofollow" target="_self">
                Войти
              </a></li><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr-register/?back=/ru/post/450098/&amp;hl=ru" rel="nofollow" target="_self">
                Регистрация
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Разделы
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/" class="footer-menu__item-link router-link-active">
                Публикации
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/news/" class="footer-menu__item-link">
                Новости
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/hubs/" class="footer-menu__item-link">
                Хабы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/companies/" class="footer-menu__item-link">
                Компании
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/users/" class="footer-menu__item-link">
                Авторы
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/sandbox/" class="footer-menu__item-link">
                Песочница
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Информация
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="/ru/docs/help/" class="footer-menu__item-link">
                Устройство сайта
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/authors/codex/" class="footer-menu__item-link">
                Для авторов
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/companies/corpblogs/" class="footer-menu__item-link">
                Для компаний
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/docs/docs/transparency/" class="footer-menu__item-link">
                Документы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/agreement" target="_blank">
                Соглашение
              </a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/confidential/" target="_blank">
                Конфиденциальность
              </a></li></ul></div></div><div class="tm-footer-menu__block"><h3 class="tm-footer-menu__block-title">
          Услуги
        </h3> <div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQLwRfQmXibiUlWaRg-BAc38s7oM3lJiaPju7qmdJsp8ysIvZ_G-Npem0njJLMozE2bPHMpDqiI5hhy/pub?start=false&amp;loop=false&amp;delayms=60000&amp;slide=id.g91a03369cd_4_297" target="_blank">
                Реклама
              </a></li><li class="tm-footer-menu__list-item"><a href="https://habrastorage.org/storage/stuff/habr/service_price.pdf" target="_blank">
                Тарифы
              </a></li><li class="tm-footer-menu__list-item"><a href="https://docs.google.com/presentation/d/e/2PACX-1vQJJds8-Di7BQSP_guHxICN7woVYoN5NP_22ra-BIo4bqnTT9FR6fB-Ku2P0AoRpX0Ds-LRkDeAoD8F/pub?start=false&amp;loop=false&amp;delayms=60000" target="_blank">
                Контент
              </a></li><li class="tm-footer-menu__list-item"><a href="https://tmtm.timepad.ru/" target="_blank">
                Семинары
              </a></li><li class="tm-footer-menu__list-item"><a href="/ru/megaprojects/" class="footer-menu__item-link">
                Мегапроекты
              </a></li></ul></div></div></div></div></div> <div class="tm-footer"><div class="tm-page-width"><div class="tm-footer__container"><!----> <div class="tm-footer__social"><a href="https://www.facebook.com/habrahabr.ru" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Facebook</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-facebook"></use></svg></a><a href="https://twitter.com/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Twitter</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-twitter"></use></svg></a><a href="https://vk.com/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>VK</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-vkontakte"></use></svg></a><a href="https://telegram.me/habr_com" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Telegram</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-telegram"></use></svg></a><a href="https://www.youtube.com/channel/UCd_sTwKqVrweTt4oAKY5y4w" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Youtube</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-youtube"></use></svg></a><a href="https://zen.yandex.ru/habr" rel="nofollow noopener noreferrer" target="_blank" class="tm-svg-icon__wrapper tm-social-icons__icon"><svg height="16" width="16" class="tm-svg-img tm-svg-icon"><title>Яндекс Дзен</title> <use xlink:href="/img/social-icons-sprite.svg#social-logo-zen"></use></svg></a></div> <DIV class="v-portal" style="display:none;"></DIV> <button class="tm-footer__link"><!---->
        Настройка языка
      </button> <a href="/ru/about" class="tm-footer__link">
        О сайте
      </a> <a href="/ru/feedback/" class="tm-footer__link">
        Техническая поддержка
      </a> <!----> <a href="/berserk-mode-nope" class="tm-footer__link">
        Вернуться на старую версию
      </a> <div class="tm-footer-copyright"><span class="tm-copyright"><span class="tm-copyright__years">© 2006–2021 </span> <span class="tm-copyright__name">«<a href="https://company.habr.com/" rel="noopener" target="_blank" class="tm-copyright__link">Habr</a>»</span></span></div></div></div></div> <!----> <!----></div> <div class="vue-portal-target"></div></div>
<script>window.__INITIAL_STATE__={"adblock":{"hasAcceptableAdsFilter":false,"hasAdblock":false},"articlesList":{"articlesList":{"450098":{"id":"450098","timePublished":"2019-04-30T06:54:36+00:00","isCorporative":false,"lang":"ru","titleHtml":"Юрий Бушмелев «Карта граблей на поле сбора и доставки логов» — расшифровка доклада","leadData":{"textHtml":"\u003Cp\u003EЛоги — важная часть системы, позволяющая понять, что она работает (либо не работает), как ожидается. В условиях микросервисной архитектуры работа с логами становится отдельной дисциплиной специальной олимпиады. Нужно решить сразу кучу вопросов:\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cul\u003E\r\n\u003Cli\u003Eкак писать логи из приложения;\u003C\u002Fli\u003E\r\n\u003Cli\u003Eкуда писать логи;\u003C\u002Fli\u003E\r\n\u003Cli\u003Eкак доставлять логи для хранения и обработки;\u003C\u002Fli\u003E\r\n\u003Cli\u003Eкак обрабатывать и хранить логи.\u003C\u002Fli\u003E\r\n\u003C\u002Ful\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EПрименение популярных ныне технологий контейнеризации добавляет песочка поверх граблей на поле вариантов решения задачи.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EКак раз об этом расшифровка доклада Юрия Бушмелева &quot;Карта граблей на поле сбора и доставки логов&quot; \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cdiv class=\"oembed\"\u003E\u003Cdiv\u003E\u003Cdiv style=\"left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.2493%;\"\u003E\u003Ciframe src=\"https:\u002F\u002Fwww.youtube.com\u002Fembed\u002FNAeedJv-S3I?rel=0&amp;showinfo=1&amp;hl=en-US\" style=\"border: 0; top: 0; left: 0; width: 100%; height: 100%; position: absolute;\" allowfullscreen scrolling=\"no\"\u003E\u003C\u002Fiframe\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdiv\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EКому интересно, прошу под кат.\u003C\u002Fp\u003E","imageUrl":null,"buttonTextHtml":null,"image":null},"editorVersion":"1.0","postType":"article","postLabels":[],"author":{"scoreStats":{"score":-1,"votesCount":387},"rating":0.6,"relatedData":null,"contacts":[],"authorContacts":[],"paymentDetails":{"paymentYandexMoney":null,"paymentPayPalMe":null,"paymentWebmoney":null},"id":"690219","alias":"gecube","fullname":null,"avatarUrl":"\u002F\u002Fhabrastorage.org\u002Fgetpro\u002Fhabr\u002Favatars\u002F758\u002Fe87\u002F53e\u002F758e8753ee221a40fefb2834b63aa875.jpg","speciality":"Кубернетес, карты, два ствола"},"statistics":{"commentsCount":13,"favoritesCount":52,"readingCount":8013,"score":8,"votesCount":10},"hubs":[{"relatedData":null,"id":"221","alias":"sys_admin","type":"collective","title":"Системное администрирование","titleHtml":"Системное администрирование","isProfiled":true},{"relatedData":null,"id":"17350","alias":"s_admin","type":"collective","title":"Серверное администрирование","titleHtml":"Серверное администрирование","isProfiled":true},{"relatedData":null,"id":"20788","alias":"devops","type":"collective","title":"DevOps","titleHtml":"DevOps","isProfiled":true}],"flows":[{"id":"6","alias":"admin","title":"Администрирование"}],"relatedData":null,"textHtml":"\u003Cdiv xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1999\u002Fxhtml\"\u003E\u003Cp\u003EЛоги — важная часть системы, позволяющая понять, что она работает (либо не работает), как ожидается. В условиях микросервисной архитектуры работа с логами становится отдельной дисциплиной специальной олимпиады. Нужно решить сразу кучу вопросов:\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cul\u003E\r\n\u003Cli\u003Eкак писать логи из приложения;\u003C\u002Fli\u003E\r\n\u003Cli\u003Eкуда писать логи;\u003C\u002Fli\u003E\r\n\u003Cli\u003Eкак доставлять логи для хранения и обработки;\u003C\u002Fli\u003E\r\n\u003Cli\u003Eкак обрабатывать и хранить логи.\u003C\u002Fli\u003E\r\n\u003C\u002Ful\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EПрименение популярных ныне технологий контейнеризации добавляет песочка поверх граблей на поле вариантов решения задачи.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EКак раз об этом расшифровка доклада Юрия Бушмелева \"Карта граблей на поле сбора и доставки логов\" \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cdiv class=\"oembed\"\u003E\u003Cdiv\u003E\u003Cdiv style=\"left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.2493%;\"\u003E\u003Cdiv class=\"tm-iframe_temp\" data-src=\"https:\u002F\u002Fwww.youtube.com\u002Fembed\u002FNAeedJv-S3I?rel=0&amp;showinfo=1&amp;hl=en-US\" data-style=\"border: 0; top: 0; left: 0; width: 100%; height: 100%; position: absolute;\" id=\"\" width=\"\"\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdiv\u003E\u003C\u002Fdiv\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EКому интересно, прошу под кат.\u003C\u002Fp\u003E\u003Ca name=\"habracut\"\u003E\u003C\u002Fa\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EМеня зовут Юрий Бушмелев. Я работаю в Lazada. Я сегодня буду рассказывать про то, как мы делали наши логи, как мы их собирали, и что мы туда пишем. \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002F_9\u002Fte\u002Fo5\u002F_9teo5cvnhsihs4lyyyc_8pcx-m.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EОткуда мы? Кто мы такие? Lazada — это интернет-магазин №1 в шести странах Юго-Восточной Азии. Все эти страны у нас распределены по дата-центрам. Всего дата-центров сейчас 4. Почему это важно? Потому что некоторые решения были обусловлены тем, что между центрами есть очень слабый линк. У нас микросервисная архитектура. Я удивился, обнаружив, что у нас уже 80 микросервисов. Когда я начинал задачу с логами, их было всего 20. Плюс есть довольно большой кусок PHP legacy, с которым тоже приходится жить и мириться. Все это генерирует нам на данный момент более 6 миллионов сообщений в минуту по системе в целом. Дальше я буду показывать, как мы с этим пытаемся жить, и почему это так.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fgy\u002Ffj\u002Fdu\u002Fgyfjduafaipfx1ay5efm8xpwtdc.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EС этими 6 миллионами сообщений надо как-то жить. Что мы с ними должны сделать? 6 миллионов сообщений, которые надо:\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cul\u003E\r\n\u003Cli\u003Eотправить из приложения\u003C\u002Fli\u003E\r\n\u003Cli\u003Eпринять для доставки\u003C\u002Fli\u003E\r\n\u003Cli\u003Eдоставить для анализа и хранения.\u003C\u002Fli\u003E\r\n\u003Cli\u003Eпроанализировать\u003C\u002Fli\u003E\r\n\u003Cli\u003Eкак-то хранить.\u003C\u002Fli\u003E\r\n\u003C\u002Ful\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fvq\u002Fkr\u002Fyt\u002Fvqkrytwk4c_gjs9fza8_zn9hanu.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EКогда появилось три миллиона сообщений, у меня был примерно такой же вид. Потому что мы начинали с каких-то копеек. Понятно, что туда пишутся логи приложений. Например, не смог подключиться к базе данных, смог подключиться к базе данных, но не смог что-то прочитать. Но кроме этого, каждый наш микросервис пишет еще и access-лог. Каждый запрос, прилетевший на микросервис, падает в лог. Зачем мы это делаем? Разработчики хотят иметь возможность трейсинга. В каждом access-логе лежит поле traceid, по которому дальше специальный интерфейс раскручивает всю цепочку и красиво показывает трейс. Трейс показывает, как проходил запрос, и это помогает нашим разработчикам быстрее справляться со всякой неопознанной фигней.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fme\u002Ffd\u002F7d\u002Fmefd7deeshbhsvsjb8n7dh81ok4.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EКак с этим жить? Сейчас я вкратце расскажу поле вариантов — как вообще эта проблема решается. Как решать задачу сбора, передачи и хранения логов. \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002F0m\u002Ff8\u002F4r\u002F0mf84rxvsn0ewrqui_4egxgb2hk.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EКак писать из приложения? Понятно, что есть разные способы. В частности, есть best practice, как нам рассказывают модные товарищи. Есть old school в двух видах, как рассказывали деды. Есть другие способы. \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fle\u002F7-\u002F_n\u002Fle7-_n8o7wl8nh4g0qadwz-jucq.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EСо сбором логов примерно такая же ситуация. Вариантов решения этой конкретной части не так много. Их уже больше, но ещё не так много. \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fkn\u002Fid\u002Fo2\u002Fknido22_ecpa0cgvfjzissz3fei.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EА вот с доставкой и последующим анализом — количество вариаций начинает взрываться. Описывать каждый вариант сейчас не буду. Думаю, основные варианты на слуху у всех, кто интересовался темой.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fqu\u002Fzg\u002Fz0\u002Fquzgz0a21pgjdb0o8ek5d3nxmwc.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EЯ покажу, как мы делали это в Lazada, и как собственно все это начиналось. \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Ftu\u002Fb_\u002Fxt\u002Ftub_xtgrnyznjspm2vxf_lepv7o.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EГод назад я пришёл в Лазаду, и меня отправили на проект про логи. Там было примерно вот так. Лог из приложения писался в stdout и stderr. Все сделали по-модному. Но дальше разработчики это выкинули из стандартных потоков, а дальше там как-нибудь специалисты по инфраструктуре разберутся. Между инфраструктурными специалистами и разработчиками есть еще релизеры, которые сказали: «эээ… ну ладно, давайте их в файл завернем просто shell-ом, и все». А поскольку все это в контейнере, то завернули прям в самом контейнере, промапили внутрь каталог и положили это туда. Думаю, что всем примерно очевидно, что из этого получилось.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fl2\u002Fpl\u002Flz\u002Fl2pllz5jvccjhbz0zzxcitkrmsk.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EПосмотрим пока чуть подальше. Как мы эти логи доставляли. Кто-то выбрал td-agent, который на самом деле fluentd, но не совсем fluentd. Я так и не понял отношения этих двух проектов, но они, вроде бы, об одном и том же. И вот этот вот fluentd, написанный на Ruby, читал файлы логов, парсил их в JSON по каким-то регуляркам. Потом их отправлял в Kafka. Причем в Kafka на каждую API у нас было 4 отдельных топика. Почему 4? Потому что есть live, есть staging, и потому что есть stdout и stderr. Разработчики их плодят, а инфраструктурщики должны их создавать в Kafka. Причем, Kafka контролировалась другим отделом. Поэтому надо было создавать тикет, чтобы они создали там 4 топика на каждый api. Все про это забывали. В общем был треш и угар. \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fx9\u002F2-\u002F5s\u002Fx92-5sqis-vgly1ccyh0gjt2mxy.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EЧто мы дальше с этим делали? Мы отправляли это в кафку. Дальше из кафки половина логов улетала в Logstash. Другая половина логов делилась. Часть улетала в один Graylog, часть – в другой Graylog. В итоге всё это улетало в один кластер Elasticsearch. То есть, весь этот бардак падал в итоге туда. Так делать не надо!\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fge\u002Fw9\u002Fkz\u002Fgew9kzazsmr5pwee16cuyor6n2w.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EВот так это выглядит, если отдаленно сверху посмотреть. Не надо так делать! Здесь вот цифрами сразу отмечены проблемные места. Их на самом деле больше, но 6 — это вот прям совсем проблемные, с которыми надо что то делать. Про них я сейчас отдельно расскажу. \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002F2w\u002Fxu\u002Feb\u002F2wxuebmewhsjvjbr_9taaq5zhn4.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EВот здесь (1,2,3) у нас пишутся файлы и, соответственно, здесь сразу три грабли. \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EПервое (1) — это нам надо их куда-то писать. Не всегда хотелось бы давать API возможность писать прямо в файл. Желательно, чтобы API была изолирована в контейнере, а еще лучше – чтобы она была read-only. Я — сисадмин, поэтому у меня немного альтернативный взгляд на эти вещи.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EВторой момент (2,3) — у нас много запросов приходит в API. API пишет много данных в файл. Файлы растут. Нам их надо ротировать. Потому что иначе там никаких дисков не напасешься. Ротировать их плохо, потому что они сделаны редиректом через shell в каталог. Мы никак не можем его отротировать. Нельзя сказать приложению, чтобы оно переоткрыло дескрипторы. Потому что разработчики на тебя посмотрят как на дурака: «Какие дескрипторы? Мы вообще в stdout пишем». Инфраструктурщики сделали copytruncate в logrotate, который делает просто копию файла и транкейтит оригинал. Соответственно, между этими процессами копирования обычно и кончается место на диске.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E(4) У нас были разные форматы были в разных API. Они немножко отличались, но regexp надо было писать разные. Поскольку всё это управлялось Puppet, то там была большая вязанка классов со своими тараканами. Плюс еще td-agent большую часть времени мог есть память, тупить, он мог просто делать вид, что он работает, и ничего не делать. Снаружи понять, что он ничего не делает было невозможно. В лучшем случае он упадет, и его кто-нибудь поднимет потом. Точнее, прилетит alert, и кто-нибудь пойдет руками переподнимет. \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fx9\u002F8i\u002Fa-\u002Fx98ia-rs9owg6hl2qqkfjpza-yg.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E(6) И самый трэш и угар — это был elasticsearch. Потому что, это была старая версия. Потому что, у нас не было выделенных мастеров на тот момент. У нас были разнородные логи, у которых поля могли пересекаться. Разные логи разных приложений могли писаться с одинаковыми названиями полей, но при этом внутри могли быть разные данные. То есть, один лог приходит с Integer в поле, например, level. Другой лог приходит со String в поле level. В отсутствие статического маппинга получается такая замечательная вещь. Если после ротации индекса в elasticsearch первым прилетело сообщение со строкой, то мы живем нормально. А если вот первым прилетело с Integer, то все последующие сообщения, которые прилетели со String, просто отбрасываются. Потому что не совпадает тип поля.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fc9\u002Fym\u002Flq\u002Fc9ymlqxv89qg1oohi-lnhknyedg.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EМы начали задаваться вот этими вопросами. Мы решили не искать виноватых.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Ffl\u002Fr1\u002Fkv\u002Fflr1kvyks_o2kdciv4pekiwtbiy.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EА вот что-то делать надо! Очевидная вещь — надо завести стандарты. Некоторые стандарты у нас уже были. Некоторые мы завели чуть позже. К счастью, единый формат логов для всех API уже утвердили на тот момент. Он прописан прямо в стандарты взаимодействия сервисов. Соответственно, те, кто хочет получать логи, должны писать их в этом формате. Если кто-то не пишет логи в этом формате, значит, мы ничего не гарантируем. \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EДалее, хотелось бы завести единый стандарт на способы записи, доставки и сбора логов. Собственно, куда их писать, и чем их доставлять. Идеальная ситуация — это когда в проектах используется одна и та же библиотека. Вот есть отдельная библиотека логирования для Go, есть отдельный библиотека для PHP. Все кто у нас есть — все должны их использовать. На данный момент я бы сказал, что процентов на 80 у нас это получается. Но некоторые продолжают есть кактусы.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EИ вот там вот (на слайде) еле-еле начинает проступать «SLA на доставку логов». Его пока нет, но мы над этим работаем. Потому что это очень удобно, когда инфра говорит, что если вы пишете в таком-то формате в такое-то место и не более N сообщений в секунду, то мы это с вероятностью такой-то доставим туда-то. Это снимает кучу головной боли. Если SLA есть, то это прямо замечательно!\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fim\u002Faq\u002Faj\u002Fimaqajo2oi-qoyb--oja3i2fnyy.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EКак мы начали решать проблему? Основная грабля была с td-agent. Было непонятно, куда у нас деваются логи. Доставляются ли они? Собираются ли они? Где они вообще? Поэтому, первым пунктом было решено заменить td-agent. Варианты, на что его заменить, вкратце я здесь набросал.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EFluentd. Во-первых, я с ним сталкивался на предыдущей работе, и он там тоже периодически падал. Во-вторых, это тоже самое, только в профиль. \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EFilebeat. Чем он был удобен для нас? Тем, что он на Go, а у нас большая экспертиза в Go. Cоответственно, если что, мы могли его под себя как-то дописать. Поэтому мы его и не взяли. Чтобы даже соблазна никакого не было начинать его под себя переписывать. \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EОчевидным решением для сисадмина остаются всякие сислоги вот в таком вот количестве (syslog-ng\u002Frsyslog\u002Fnxlog).\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EЛибо написать что-то свое, но мы это отбросили, равно как и filebeat. Если что-то писать, то лучше писать что-то полезное для бизнеса. Для доставки логов лучше взять что-то готовое.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EПоэтому выбор фактически свелся к выбору между syslog-ng и rsyslog. Cклонился в сторону rsyslog просто потому, что у нас в Puppet уже были классы для rsyslog, и я не нашел между ними очевидной разницы. Что там syslog, что тут syslog. Да, у кого-то документация хуже, у кого-то лучше. Тот умеет так, а тот — по-другому.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fxl\u002Fwg\u002F7y\u002Fxlwg7yv4du2k8ktumnmdltwci78.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EИ немножко про rsyslog. Во-первых, он клёвый, потому что у него есть много модулей. У него человеко-понятный RainerScript (современный язык конфигурации). Офигенный бонус, что мы могли его штатными средствами сэмулировать поведение td-agent, и для приложений ничего не поменялось. То есть, мы меняем td-agent на rsyslog, а все остальное пока не трогаем. И сразу получаем работающую доставку. Далее, mmnormalize — это офигенная штука в rsyslog. Она позволяет парсить логи, но не с помощью Grok и regexp. Она делает abstract syntax tree. Она парсит логи примерно, как компилятор парсит исходники. Это позволяет работать очень быстро, жрать мало CPU, и, вообще, прям очень клёвая штука. Есть куча других бонусов. Я о них не буду останавливаться.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Ftf\u002F6w\u002Fc0\u002Ftf6wc0eulg65fu-dy64mmkjyr4g.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EУ rsyslog есть ещё куча недостатков. Они примерно такие же, как и бонусы. Основные проблемы — надо уметь его готовить, и надо подбирать версию.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fp-\u002F2l\u002Fl5\u002Fp-2ll5-sxmfivl2136kopu1oipi.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EМы решили что будем писать логи в unix socket. Причем не в \u002Fdev\u002Flog, потому что там у нас каша из системных логов, там journald в этом pipeline. Поэтому давайте писать в кастомный сокет. Мы его прицепим к отдельному ruleset. Не будем ничего мешать. Будет все прозрачно и понятно. Так мы собственно и сделали. Каталог с этими сокетами стандартизирован и пробрасывается во все контейнеры. Контейнеры могут видеть нужный им socket, открывать и писать него. \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EПочему не файл? Потому что все читали \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fbadoo\u002Fblog\u002F280606\u002F\"\u003Eстатью про Бадушечку\u003C\u002Fa\u003E, которая пыталась пробросить файл в docker, и обнаруживалось, что после рестарта rsyslog меняется file descriptor, и docker теряет этот файл. Он держит открытым что-то другое, но уже не тот сокет куда пишут. Мы решили, что мы обойдем эту проблему, и, заодно, обойдем проблему блокировки.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fri\u002Fkn\u002Fr9\u002Friknr9odspcwgtmywqapeq1htmi.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003ERsyslog делает действия указанные на слайде и отправляет логи либо в релей, либо в Kafka. Kafka соответствует старому способу. Релей — это я попытался использовать чисто rsyslog для доставки логов. Без Message Queue, стандартными средствами rsyslog. В принципе, это работает.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fwh\u002Fbl\u002Ffv\u002Fwhblfvj4lnbmdryfev1fypctp74.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EНо есть нюансы с тем, как запихивать их потом в эту часть (Logstash\u002FGraylog\u002FES). Эта часть (rsyslog-rsyslog) используется между датацентрами. Здесь compressed tcp link, который позволяет сэкономить bandwidth и, соответственно, как-то увеличить вероятность того, что мы получим какие-то логи из другого датацентра в условиях, когда канал забит. Потому что, нас есть Индонезия, в которой все плохо. Вот там эта постоянная проблема.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fzx\u002Fbx\u002Fgi\u002Fzxbxgimmd3xniduuuw0spq0vg1o.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EМы задумались над тем как нам собственно промониторить, с какой вероятностью логи, которые мы записали из приложения, доезжают до того конца? Мы решили завести метрики. У rsyslog есть свой модуль сбора статистики, в котором есть какие-то счетчики. Например, он может показать вам размер очереди, или сколько сообщений пришло в такой-то action. Из них уже можно что-то взять. Плюс, у него есть кастомные счетчики, которые можно настроить, и он будет вам показывать, например, количество сообщений, который записало какое-то API. Далее, я написал rsyslog_exporter на Python, и мы все это отправили в Prometheus и построили графики. Метрики Graylog очень хотелось, но пока мы не успели их настроить.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fkq\u002Fb0\u002F-1\u002Fkqb0-1ox3sevtkje8qnb7ekp1is.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EС чем возникли проблемы? Проблемы возникли с тем, что у нас обнаружилось (ВНЕЗАПНО!), что наши Live API пишут по 50к сообщений в секунду. Это только Live API без staging. А Graylog нам показывает только 12 тысяч сообщений в секунду. И возник резонный вопрос, а где остатки-то? Из чего мы сделали вывод, что Graylog просто не справляется. Посмотрели, и, действительно, Graylog с Elasticsearch не осиливали этот поток.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EДалее, другие открытия, которые мы сделали в процессе.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EЗапись в socket блокируются. Как это случилось? Когда я использовал rsyslog для доставки, в какой-то момент у нас сломался канал между датацентрами. Встала доставка в одном месте, встала доставка другом месте. Все это докатилась до машины с API, которые пишут в сокет rsyslog. Там заполнилась очередь. Потом заполнилась очередь на запись в unix socket, которая по умолчанию 128 пакетов. И следующий write() в приложении блокируется. Когда мы смотрели в библиотечку, которой пользуемся в приложениях на Go, там было написано, что запись в сокет происходит в неблокирующемся режиме. Мы были уверены, что ничего не блокируется. Потому что мы читали \u003Ca href=\"https:\u002F\u002Fhabr.com\u002Fru\u002Fcompany\u002Fbadoo\u002Fblog\u002F280606\u002F\"\u003Eстатью про Бадушечку\u003C\u002Fa\u003E, которая про это написала. Но есть момент. Вокруг этого вызова был еще бесконечный цикл, в котором постоянно происходила попытка запихать сообщение в сокет. Вот его мы не заметили. Пришлось переписать библиотеку. С тех пор она несколько раз менялась, но сейчас мы избавились от блокировок во всех подсистемах. Поэтому, можно останавливать rsyslog, и ничего не упадет.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EНужно мониторить размер очередей, что помогает не наступить на эти грабли. Во-первых, мы можем мониторить, когда мы начинаем терять сообщения. Во-вторых, можем мониторить что у нас в принципе проблемы с доставкой.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EИ еще неприятный момент — амплификация в 10 раз в микросервисной архитектуре — это очень легко. У нас входящих запросов не так много, но из-за графа, по которому бегают эти сообщения дальше, из-за access-логов, мы реально увеличиваем нагрузку по логам примерно раз в десять. Я к сожалению не успел посчитать точные цифры, но микросервисы — они такие. Это надо иметь в виду. Получается, что на данный момент подсистема сбора логов — самая нагруженная в Lazada. \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002F6a\u002Ffd\u002Fmi\u002F6afdmitt6iid3yqd6cmdgq8_lkq.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EКак решить проблему elasticsearch? Если надо быстро получить логи в одном месте, чтобы не бегать по всем машинам, и не собирать их там, используйте файловое хранилище. Это гарантированно работает. Оно делается из любого сервера. Надо просто натыкать туда дисков и поставить syslog. После этого у вас гарантированно в одном месте все логи есть. Дальше уже можно будет неспешно настраивать elasticsearch, graylog, что-нибудь еще. Но у вас уже будут все логи, и, причем, вы их можете хранить, насколько хватает дисковых массивов.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fcx\u002F1d\u002Fg3\u002Fcx1dg33kkvufonoxpwrrpmmabza.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EНа момент моего доклада схема стала выглядеть вот так. В файл мы практически перестали писать. Сейчас, скорее всего, отлючим остатки. На локальных машинах, на которых запущены API, в файлы мы писать перестанем. Во-первых, есть файловое хранилище, которое работает очень хорошо. Во-вторых, на этих машинах постоянно кончается место, надо его постоянно мониторить.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EВот эта часть с Logstash и Graylog, она реально парит. Поэтому надо от нее избавиться. Надо выбрать что-то одно.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fw4\u002Fbj\u002Fpo\u002Fw4bjpoxgbdggewegwtrg1ao9mpi.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EМы решили выкинуть Logstash и Kibana. Потому что у нас есть отдел безопасности. Какая связь? Связь в том что Kibana без X-Pack и без Shield не позволяет разграничить права доступа к логам. Поэтому взяли Graylog. В нем все это есть. Он мне не нравится, но он работает. Мы купили нового железа, поставили там свежий Graylog и перенесли все логи со строгими форматами в отдельный Graylog. Мы решили проблему с разными типами одинаковых полей организационно.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fcn\u002Fhr\u002F41\u002Fcnhr41tyx4sf0c0skbjqrgbyb90.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EЧто собственно в новый Graylog входит. Мы просто записали все в докер. Взяли кучу серверов, раскатали три инстанса Kafka, 7 серверов Graylog версии 2.3 (потому что хотелось Elasticsearch версии 5). Все это на рейдах из HDD подняли. Увидели indexing rate до 100 тысяч сообщений в секунду. Увидели цифру что 140 терабайт данных в неделю. \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fwv\u002Fyd\u002Fyj\u002Fwvydyj9d_mfo3xztj9elcbvpdaa.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EИ опять грабли! У нас грядут две распродажи. Мы переехали за 6 миллионов сообщений. У нас Graylog не успевает прожевывать. Как-то надо опять выживать. \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fxf\u002F2j\u002Flc\u002Fxf2jlclf52i3oi3nsxdksth-xpe.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EВыжили мы вот так. Добавили еще немножко серверов и SSD. На данный момент мы живем вот таким способом. Сейчас мы прожёвываем уже 160к сообщений в секунду. Мы еще не уперлись в лимит, поэтому пока непонятно, сколько мы реально сможем вытянуть из этого. \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fbn\u002Fck\u002Fss\u002Fbnckssznjbmcrm7v4zh7yhgoltw.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EВот такие у нас планы на будущее. Из них, реально, самое важное, наверное, high availability. У нас его пока нет. Несколько машин настроены одинаково, но едет пока все через одну машину. Надо потратить время, чтобы настроить failover между ними.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EСобрать метрики с Graylog.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EСделать rate limit чтобы у нас одна, сошедшая с ума API, не убивала нам bandwidth и все остальное.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EИ наконец, подписать какой-то SLA c разработчиками, что мы можем обслужить вот столько. Если вы пишете больше, то извините.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EИ написать документацию.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cimg src=\"\u002Fimg\u002Fimage-loader.svg\" data-src=\"https:\u002F\u002Fhabrastorage.org\u002Fwebt\u002Fcc\u002Fhr\u002Faz\u002Fcchrazzrhareykxd78meljitrso.png\"\u002F\u003E\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EКратенько, итоги всего, что мы пережили. Во-первых, стандарты. Во-вторых, syslog — торт. В-третьих, rsyslog работает именно вот так, как написано на слайде. И давайте перейдем к вопросам.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EВопросы\u003C\u002Fstrong\u003E.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EВопрос\u003C\u002Fstrong\u003E: Почему все-таки решили не брать… (filebeat?)\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EОтвет\u003C\u002Fstrong\u003E: Надо писать в файл. Очень не хотелось. Когда у тебя API пишет тысячи сообщений в секунду, ты даже если раз в час будешь ротировать, то это все равно не вариант. Можно писать в pipe. На что меня разработчики спросили: «А что будет если, процесс в который мы пишем, упадет»? Я просто не нашел, что им ответить, и сказал: «Ну ок, давайте мы не будем так делать».\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EВопрос\u003C\u002Fstrong\u003E: Почему вы не пишете логи просто в HDFS?\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EОтвет\u003C\u002Fstrong\u003E: Это следующий этап. Мы про него подумали самом начале, но, поскольку, в данный момент нет ресурсов этим заниматься, то он у нас висит в long term solution.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EВопрос\u003C\u002Fstrong\u003E: Колоночный формат был бы более подходящий.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EОтвет\u003C\u002Fstrong\u003E: Я все понимаю. Мы \"за\" обеими руками. \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EВопрос\u003C\u002Fstrong\u003E: Вы пишете в rsyslog. Там можно и TCP, и UDP. Но если UDP, то тогда как вы гарантируете доставку?\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EОтвет\u003C\u002Fstrong\u003E: Есть два момента. Первый, я сразу всем говорю, что мы не гарантируем доставку логов. Потому что, когда разработчики приходят и говорят: «А давайте мы туда начнем писать финансовые данные, а вы будете их нам куда-то складывать на случай, если что-то случится», мы им отвечаем «Отлично! Давайте вы начнете блокироваться на записи в сокет, и делать это в транзакциях, чтобы гарантированно вы нам это в сокет положили и убедились, что мы с той стороны это получили.» И в этот момент всем сразу становится не надо. А раз не надо, то какие к нам вопросы? Если вы не хотите гарантировать запись в сокет, то зачем нам гарантировать доставку? Мы делаем best effort. Мы реально стараемся доставить как можно больше и как можно лучше, но мы не даем 100% гарантии. Поэтому не надо писать туда финансовые данные. Для этого есть базы данных с транзакциями.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EВопрос\u003C\u002Fstrong\u003E: Когда API генерирует какое-то сообщение в лог и передает управление микросервисам, то не сталкивались ли вы с проблемой, что сообщения от разных микросервисов приходят в неправильном порядке? Из-за этого возникает путаница.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EОтвет\u003C\u002Fstrong\u003E: Это нормально, что они приходят в разном порядке. К этому надо быть готовым. Потому что любая сетевая доставка вам не гарантирует порядок, или надо тратить специально ресурсы на это. Если возьмем файловые хранилища, то каждая API сохраняет логи в свой файл. Вернее там rsyslog раскладывается их по каталогам. У каждого API там есть свои логи, куда можно пойти и посмотреть, и потом по timestamp в этом логе можно их посопоставлять. Если они идут смотреть в Graylog, то там они отсортируется по timestamp. Там всё будет хорошо.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EВопрос\u003C\u002Fstrong\u003E: Timestamp может отличаться на миллисекунды.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EОтвет\u003C\u002Fstrong\u003E: Timestamp генерит сама API. В этом, собственно, вся фишка. У нас есть NTP. API генерит timestamp уже в самом сообщении. Его не rsyslog добавляет.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EВопрос\u003C\u002Fstrong\u003E: Не очень понятно взаимодействие между датацентрами. В рамках датацентра понятно как логи собрали, обработали. Как проиходит взаимодействие между датацентрами? Или каждый датацентр живет своей жизнью?\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EОтвет\u003C\u002Fstrong\u003E: Почти. У нас каждая страна находится в каком-то одном датацентре. У нас нет на данный момент размазывания, чтобы одна страна была размещена по разным датацентрам. Поэтому не надо их объединять. Внутри каждого центра есть Log Relay. Это Rsyslog сервер. На самом деле две менеджмент машины. Они одинаково настроены. Но пока просто трафик идет через одну из них. Она логи все агрегирует. У нее есть дисковая очередь на всякий случай. Она жмет логи, и отправляет их в центральный датацентр (сингапурский), где дальше они уже отравляются в Graylog. И в каждом датацентре есть свой файловый storage. В случае, если у нас пропала связь, мы имеем все логи там. Они там останутся. Они там будут сохранены.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EВопрос\u003C\u002Fstrong\u003E: При нештатных ситациях оттуда вы получаете логи?\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EОтвет\u003C\u002Fstrong\u003E: Можно пойти туда (в файловое хранилище) и посмотреть.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EВопрос\u003C\u002Fstrong\u003E: Как вы мониторите то, что вы не теряете логи?\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EОтвет\u003C\u002Fstrong\u003E: Мы их теряем на самом деле, и мы это мониторим. Мониторинг запустили месяц назад. В библиотеке, которую используют Go API, есть метрики. Она умеет считать, сколько раз она не смогла записать в socket. Там на данный момент есть хитрая эвристика. Там есть буфер. Он пытается записывать из него сообщение в socket. Если буфер переполнится, он начинает их дропать. И считает сколько он их подроппал. Если там начинает переполняться счетчики, мы об этом узнаем. Они сейчас приезжают также в prometheus, и в Grafana можно посмотреть графики. Можно настроить оповещения. Но пока непонятно, кому их отправлять.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EВопрос\u003C\u002Fstrong\u003E: В elasticsearch вы с резервированием храните логи. Сколько у вас реплик?\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EОтвет\u003C\u002Fstrong\u003E: Одна реплика.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EВопрос\u003C\u002Fstrong\u003E: Это всего одна реплика?\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EОтвет\u003C\u002Fstrong\u003E: Это мастер и реплика. В двух экземплярах данные хранятся.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EВопрос\u003C\u002Fstrong\u003E: Размер буфера rsyslog вы как-то подкручивали? \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EОтвет\u003C\u002Fstrong\u003E: Мы пишем дейтаграммы в кастомный unix socket. Это нам сразу же накладывает ограничение 128 килобайт. Мы не можем записать в него больше. Мы прописали это в стандарт. Кто хочет попадать в стореджи, те пишут 128 килобайт. Библиотеки, причем, обрезают, и ставят флаг, что сообщение обрезано. У нас стандарте самого сообщения есть специальные поле, которое показывает было ли оно обрезано при записи или нет. Так что мы имеем возможность отследить и этот момент.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EВопроc\u003C\u002Fstrong\u003E: Пишете ли вы битые JSON? \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EОтвет\u003C\u002Fstrong\u003E: Битый JSON будет отброшен либо во время relay, потому что слишком большой пакет. Либо будет отброшен Graylog, потому что не сможет JSON распарсить. Но здесь есть нюансы, которые надо фиксить, и они большей частью завязаны на rsyslog. Я уже заполнил туда несколько issue, над которыми надо еще работать.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EВопроc\u003C\u002Fstrong\u003E: Почему Kafka? Пробовали ли RabbitMQ? Не складывается Graylog при таких нагрузках?\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EОтвет\u003C\u002Fstrong\u003E: У нас с Graylog не складывается. А Graylog у нас складывается. С ним реально проблемно. Он своеобразная штука. И, на самом деле, он не нужен. Я бы предпочел писать из rsyslog напрямую в elasticsearch и смотреть потом Kibana. Но надо утрясти вопрос с безопасниками. Это возможный вариант нашего развития, когда мы выкинем Graylog и будем использовать Kibana. Logstash использовать смысла не будет. Потому что, я могу все это же самое сделать rsyslog. И у него есть модуль для записи в elasticsearch. С Graylog мы пытаемся как-то жить. Мы его даже немножко потюнили. Но там есть еще пространство для улучшений.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003EНасчет Kafka. Так исторически сложилось. Когда я пришел, она уже была, и в нее уже писали логи. Мы просто подняли наш кластер и переехали в него логами. Мы его менеджим, мы знаем, как он себя чувствует. Насчет RabbitMQ… у нас не складывается c RabbitMQ. А RabbitMQ у нас складывается. У нас продакшне он есть, и с ним были проблемы. Сейчас бы перед распродажей его зашаманили, и он стал нормально работать. Но до этого я был не готов его выпускать в продакшн. Есть еще один момент. Graylog умеет читать версию AMQP 0.9, а rsyslog умеет писать версию AMQP 1.0. И нет ни одного решения, которое посередине умеет и то, и другое. Есть либо то либо другое. Поэтому на данный момент только Kafka. Но там тоже свои нюансы. Потому что omkafka той версии rsyslog, которой мы используем, может потерять вот весь буфер сообщений, которое она выгребла из rsyslog. Пока мы с этим миримся. \u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EВопроc\u003C\u002Fstrong\u003E: Вы используете Kafka потому, что она у вас в была? Больше ни для каких целей не используется?\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EОтвет\u003C\u002Fstrong\u003E: Kafka, которая была, используется командой Data Sсience. Это совсем отдельный проект, про который я, к сожалению, ничего сказать не могу. Я не в курсе. Она была в ведении команды Data Sсience. Когда логи заводили решили использовать ее, чтобы не ставить еще и свою. Сейчас мы обновили Graylog, и у нас потерялась совместимость, потому что там старая версия Kafka. Нам пришлось завести свою. Заодно мы избавились от этих четырех топиков на каждый API. Мы сделали один широкий топик на все live, один широкий широкий топик на все staging и просто все туда пуляем. Graylog все это параллельно выгребает.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EВопроc\u003C\u002Fstrong\u003E: Зачем нужно вот это шаманство с сокетами? Пробовали ли использовать log-драйвер syslog для контейнеров.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EОтвет\u003C\u002Fstrong\u003E: На тот момент когда мы этим вопросом задавались, с докером у нас отношения были напряженные. Это был docker 1.0 или 0.9. Docker сам по себе был странный. Во-вторых, если в него еще и логи пихать… У меня есть непроверенное подозрение, что он пропускает все логи через себя, через демон докера. Если у нас одно API сходит с ума, то остальные API утыкаются в то, что они не могут отправить stdout и stderr. Я не знаю к чему это приведет. У меня есть подозрение на уровне ощущения, что не надо syslog-драйвер докера вот в этом месте использовать. У нашего отдела функционального тестирование есть свой собственный кластерочек Graylog с логами. Они используют log-драйверы докера и у них там вроде бы даже все хорошо. Но они GELF сразу пишут в Graylog. Мы на тот момент, когда все это затевали, нам надо было чтобы оно просто работало. Возможно потом, когда кто-то придет и скажет, что оно уже сто лет работает нормально, мы попробуем.\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EВопроc\u003C\u002Fstrong\u003E: Вы доставку между датацентрами делаете на rsyslog. Почему не на Kafka?\u003C\u002Fp\u003E\u003Cbr\u002F\u003E\r\n\u003Cp\u003E\u003Cstrong\u003EОтвет\u003C\u002Fstrong\u003E: Мы делаем и так, и так на самом деле. По двум причинам. Если канал совсем убитый, то у нас все логи даже в сжатом виде не пролазят него. А кафка позволяет их просто терять в процессе. Мы этим способом избавляемся от залипания вот этих логов. Мы просто используем Kafka в этом случае напрямую. Eсли у нас канал хороший и хочется освободить его, то мы используем их rsyslog. Но на самом деле можно его настроить его так, чтобы он сам дропал то, что не пролезло. На данный момент мы просто где-то используем доставку rsyslog напрямую, где-то Kafka.\u003C\u002Fp\u003E\u003C\u002Fdiv\u003E","tags":[{"titleHtml":"devops"},{"titleHtml":"elasticsearch"},{"titleHtml":"rsyslog"},{"titleHtml":"graylog"},{"titleHtml":"kafka"},{"titleHtml":"сбор логов"},{"titleHtml":"логирование"}],"metadata":{"stylesUrls":[],"scriptUrls":[],"shareImageUrl":"https:\u002F\u002Fhabr.com\u002Fshare\u002Fpublication\u002F450098\u002F3a4ab30ede0a7cb85b099081b994322c\u002F","shareImageWidth":1200,"shareImageHeight":630,"vkShareImageUrl":"https:\u002F\u002Fhabr.com\u002Fshare\u002Fpublication\u002F450098\u002F3a4ab30ede0a7cb85b099081b994322c\u002F?format=vk","schemaJsonLd":"{\"@context\":\"http:\\\u002F\\\u002Fschema.org\",\"@type\":\"Article\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fpost\\\u002F450098\\\u002F\"},\"headline\":\"Юрий Бушмелев «Карта граблей на поле сбора и доставки логов» — расшифровка доклада\",\"datePublished\":\"2019-04-30T09:54:36+03:00\",\"dateModified\":\"2019-10-24T16:48:25+03:00\",\"author\":{\"@type\":\"Person\",\"name\":\"gecube\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Habr\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fa_\\\u002Flk\\\u002F9m\\\u002Fa_lk9mjkccjox-zccjrpfolmkmq.png\"}},\"description\":\"Логи &mdash; важная часть системы, позволяющая понять, что она работает (либо не работает), как ожидается. В условиях микросервисной архитектуры работа с логами станов...\",\"url\":\"https:\\\u002F\\\u002Fhabr.com\\\u002Fru\\\u002Fpost\\\u002F450098\\\u002F#post-content-body\",\"about\":[\"h_sys_admin\",\"h_s_admin\",\"h_devops\",\"f_admin\"],\"image\":[\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002F_9\\\u002Fte\\\u002Fo5\\\u002F_9teo5cvnhsihs4lyyyc_8pcx-m.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fgy\\\u002Ffj\\\u002Fdu\\\u002Fgyfjduafaipfx1ay5efm8xpwtdc.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fvq\\\u002Fkr\\\u002Fyt\\\u002Fvqkrytwk4c_gjs9fza8_zn9hanu.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fme\\\u002Ffd\\\u002F7d\\\u002Fmefd7deeshbhsvsjb8n7dh81ok4.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002F0m\\\u002Ff8\\\u002F4r\\\u002F0mf84rxvsn0ewrqui_4egxgb2hk.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fle\\\u002F7-\\\u002F_n\\\u002Fle7-_n8o7wl8nh4g0qadwz-jucq.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fkn\\\u002Fid\\\u002Fo2\\\u002Fknido22_ecpa0cgvfjzissz3fei.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fqu\\\u002Fzg\\\u002Fz0\\\u002Fquzgz0a21pgjdb0o8ek5d3nxmwc.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Ftu\\\u002Fb_\\\u002Fxt\\\u002Ftub_xtgrnyznjspm2vxf_lepv7o.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fl2\\\u002Fpl\\\u002Flz\\\u002Fl2pllz5jvccjhbz0zzxcitkrmsk.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fx9\\\u002F2-\\\u002F5s\\\u002Fx92-5sqis-vgly1ccyh0gjt2mxy.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fge\\\u002Fw9\\\u002Fkz\\\u002Fgew9kzazsmr5pwee16cuyor6n2w.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002F2w\\\u002Fxu\\\u002Feb\\\u002F2wxuebmewhsjvjbr_9taaq5zhn4.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fx9\\\u002F8i\\\u002Fa-\\\u002Fx98ia-rs9owg6hl2qqkfjpza-yg.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fc9\\\u002Fym\\\u002Flq\\\u002Fc9ymlqxv89qg1oohi-lnhknyedg.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Ffl\\\u002Fr1\\\u002Fkv\\\u002Fflr1kvyks_o2kdciv4pekiwtbiy.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fim\\\u002Faq\\\u002Faj\\\u002Fimaqajo2oi-qoyb--oja3i2fnyy.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fxl\\\u002Fwg\\\u002F7y\\\u002Fxlwg7yv4du2k8ktumnmdltwci78.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Ftf\\\u002F6w\\\u002Fc0\\\u002Ftf6wc0eulg65fu-dy64mmkjyr4g.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fp-\\\u002F2l\\\u002Fl5\\\u002Fp-2ll5-sxmfivl2136kopu1oipi.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fri\\\u002Fkn\\\u002Fr9\\\u002Friknr9odspcwgtmywqapeq1htmi.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fwh\\\u002Fbl\\\u002Ffv\\\u002Fwhblfvj4lnbmdryfev1fypctp74.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fzx\\\u002Fbx\\\u002Fgi\\\u002Fzxbxgimmd3xniduuuw0spq0vg1o.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fkq\\\u002Fb0\\\u002F-1\\\u002Fkqb0-1ox3sevtkje8qnb7ekp1is.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002F6a\\\u002Ffd\\\u002Fmi\\\u002F6afdmitt6iid3yqd6cmdgq8_lkq.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fcx\\\u002F1d\\\u002Fg3\\\u002Fcx1dg33kkvufonoxpwrrpmmabza.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fw4\\\u002Fbj\\\u002Fpo\\\u002Fw4bjpoxgbdggewegwtrg1ao9mpi.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fcn\\\u002Fhr\\\u002F41\\\u002Fcnhr41tyx4sf0c0skbjqrgbyb90.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fwv\\\u002Fyd\\\u002Fyj\\\u002Fwvydyj9d_mfo3xztj9elcbvpdaa.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fxf\\\u002F2j\\\u002Flc\\\u002Fxf2jlclf52i3oi3nsxdksth-xpe.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fbn\\\u002Fck\\\u002Fss\\\u002Fbnckssznjbmcrm7v4zh7yhgoltw.png\",\"https:\\\u002F\\\u002Fhabrastorage.org\\\u002Fwebt\\\u002Fcc\\\u002Fhr\\\u002Faz\\\u002Fcchrazzrhareykxd78meljitrso.png\"]}","metaDescription":"Логи — важная часть системы, позволяющая понять, что она работает (либо не работает), как ожидается. В условиях микросервисной архитектуры работа с логами становится отдельной дисциплиной специальной...","mainImageUrl":null,"amp":false},"polls":[],"commentsEnabled":true,"rulesRemindEnabled":false,"votesEnabled":true,"status":"published","plannedPublishTime":null,"checked":null,"isEditorial":false}},"articlesIds":{},"isLoading":false,"pagesCount":{},"route":{},"reasonsList":null,"view":"cards","lastVisitedRoute":{},"ssrCommentsArticleIds":[""],"karma":{}},"authorContribution":{"authors":{}},"betaTest":{"currentAnnouncement":null,"announcements":{},"announcementCards":null,"announcementComments":{},"announcementCommentThreads":{},"announcementCommentingStatuses":{},"archivedList":[]},"authorStatistics":{"articleRefs":{},"articleIds":{},"pagesCount":{},"route":{},"viewsCount":[],"maxStatsCount":{}},"career":{"seoLandings":[],"hubs":"sys_admin,s_admin,devops"},"comments":{"articleComments":{},"searchCommentsResults":null,"previewComment":null,"pagesCount":null,"commentAccess":{},"scrollParents":{},"pageArticleComments":{"lastViewedComment":0,"postId":null,"lastCommentTimestamp":"","moderated":[],"moderatedIds":[],"commentRoute":""}},"companies":{"companyRefs":{},"companyIds":{},"companyTopIds":{},"pagesCount":{},"companyProfiles":{},"companiesCategories":[],"companiesCategoriesTotalCount":0,"companiesWidgets":{},"companiesWorkers":{},"companiesFans":{},"route":{},"isLoading":false,"companyWorkersLoading":false,"companyFansLoading":false,"vacancies":{}},"companiesContribution":{"hubs":{},"flows":{},"companyRefs":{}},"companyHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"conversation":{"messages":[],"respondent":null,"isLoadMore":false},"conversations":{"conversations":[],"unreadCount":0,"pagesCount":0,"isLoadMore":false},"desktopState":{"desktopFl":null,"desktopHl":null,"isChecked":false,"isLoginDemanded":false},"dfp":{"slotsDict":{}},"docs":{"menu":{},"articles":{},"mainMenu":[],"loading":{"main":false,"dropdown":false,"article":false}},"feature":{"isProbablyVisible":"true"},"flows":{"flows":[{"alias":"develop","id":1,"route":{"name":"FLOW_PAGE","params":{"flowName":"develop"}}},{"alias":"admin","id":6,"route":{"name":"FLOW_PAGE","params":{"flowName":"admin"}}},{"alias":"design","id":2,"route":{"name":"FLOW_PAGE","params":{"flowName":"design"}}},{"alias":"management","id":3,"route":{"name":"FLOW_PAGE","params":{"flowName":"management"}}},{"alias":"marketing","id":4,"route":{"name":"FLOW_PAGE","params":{"flowName":"marketing"}}},{"alias":"popsci","id":7,"route":{"name":"FLOW_PAGE","params":{"flowName":"popsci"}}}]},"global":{"isPwa":false,"device":"desktop","isHabrCom":true},"hubs":{"hubRefs":{},"hubIds":{},"pagesCount":{},"isLoading":false,"route":{}},"hubsBlock":{"hubRefs":{},"hubIds":{}},"i18n":{"fl":"ru","hl":"ru"},"info":{"infoPage":{},"isLoading":true},"location":{"urlStruct":{"protocol":null,"slashes":null,"auth":null,"host":null,"port":null,"hostname":null,"hash":null,"search":null,"query":{},"pathname":null,"path":null,"href":""},"searchQuery":null},"me":{"user":null,"ppgDemanded":false,"karmaResetInfo":{"canReincarnate":null,"wasReincarnated":null,"currentScore":null},"notes":null},"mostReadingList":{"mostReadingListIds":[],"mostReadingListRefs":null,"promoPost":null},"pinnedPost":{"pinnedPost":null},"ppa":{"articles":{},"card":null,"transactions":null,"totalTransactions":null,"isAccessible":null},"projectsBlocks":{"activeBlocks":{}},"pullRefresh":{"shouldRefresh":false},"sandbox":{"articleIds":[],"articleRefs":{},"pagesCount":null,"route":{},"lastVisitedRoute":{},"isLoading":false},"settingsOther":{"inputs":{"uiLang":{"errors":[],"ref":null,"value":""},"articlesLangEnglish":{"errors":[],"ref":null,"value":false},"articlesLangRussian":{"errors":[],"ref":null,"value":false},"agreement":{"errors":[],"ref":null,"value":false},"email":{"errors":[],"ref":null,"value":true},"digest":{"errors":[],"ref":null,"value":true}}},"similarList":{"similarListIds":[],"similarListRefs":null},"ssr":{"error":null,"isDataLoaded":false,"isDataLoading":false,"isHydrationFailed":false,"isServer":false},"userHubsContribution":{"contributionRefs":{"hubRefs":{},"hubIds":{}}},"userInvites":{"availableInvites":0,"usedInvitesIds":[],"usedInvitesRefs":{},"usedInvitesPagesCount":0,"unusedInvitesIds":[],"unusedInvitesRefs":{},"unusedInvitesPagesCount":0},"users":{"authorRefs":{},"authorIds":{},"pagesCount":{},"authorProfiles":{},"userHubs":{},"userInvitations":{},"authorFollowers":{},"authorFollowed":{},"karmaStats":[],"statistics":null,"isLoading":false,"authorFollowersLoading":false,"authorFollowedLoading":false,"userHubsLoading":false,"userInvitationsLoading":false,"route":{}},"viewport":{"prevScrollY":{},"scrollY":0,"width":0},"tracker":{"items":{},"pagesCache":{},"markedViewedSilently":{},"markedRead":{},"unreadCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null},"unviewedCounters":{"applications":null,"system":null,"mentions":null,"subscribers":null,"posts_and_comments":null}}};(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());</script>
<script src="https://assets.habr.com/habr-web/js/chunk-vendors.c2c3fc9a.js" defer></script><script src="https://assets.habr.com/habr-web/js/app.c0af73e7.js" defer></script>



    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    </script>
  
  <script type="text/javascript" >
    (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
    m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
    (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

    ym(24049213, "init", {
      defer:true,
      trackLinks:true,
      accurateTrackBounce:true,
      webvisor:false,
    });
  </script>
  <noscript>
    <div>
      <img src="https://mc.yandex.ru/watch/24049213" style="position:absolute; left:-9999px;" alt="" />
    </div>
  </noscript>
  
    <script type="text/javascript">
      window.addEventListener('load', function () {
        setTimeout(() => {
          const img = new Image();
          img.src = 'https://vk.com/rtrg?p=VK-RTRG-421343-57vKE';
        }, 0);
      });
    </script>
  
</body>
</html>
